{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run Experiments\n",
        "\n",
        "You can use the Azure Machine Learning SDK to run code experiments that log metrics and generate outputs. This is at the core of most machine learning operations in Azure Machine Learning.\n",
        "\n",
        "## Connect to your workspace\n",
        "\n",
        "All experiments and associated resources are managed within your Azure Machine Learning workspace. In most cases, you should store the workspace configuration in a JSON configuration file. This makes it easier to reconnect without needing to remember details like your Azure subscription ID. You can download the JSON configuration file from the blade for your workspace in the Azure portal, but if you're using a Compute Instance within your workspace, the configuration file has already been downloaded to the root folder.\n",
        "\n",
        "The code below uses the configuration file to connect to your workspace.\n",
        "\n",
        "> **Note**: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1649363615859
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ready to use Azure ML 1.41.0 to work with dp100_mlws\n"
          ]
        }
      ],
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run an experiment\n",
        "\n",
        "One of the most fundamental tasks that data scientists need to perform is to create and run experiments that process and analyze data. In this exercise, you'll learn how to use an Azure ML *experiment* to run Python code and record values extracted from data. In this case, you'll use a simple dataset that contains details of patients that have been tested for diabetes. You'll run an experiment to explore the data, extracting statistics, visualizations, and data samples. Most of the code you'll use is fairly generic Python, such as you might run in any data exploration process. However, with the addition of a few lines, the code uses an Azure ML *experiment* to log details of the run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649363619696
        },
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "from azureml.core import Experiment\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "# Create an Azure ML experiment in your workspace\n",
        "experiment = Experiment(workspace=ws, name=\"mslearn-diabetes\")\n",
        "\n",
        "# Start logging data from the experiment, obtaining a reference to the experiment run\n",
        "run = experiment.start_logging()\n",
        "print(\"Starting experiment:\", experiment.name)\n",
        "\n",
        "# load the data from a local file\n",
        "data = pd.read_csv('data/diabetes.csv')\n",
        "\n",
        "# Count the rows and log the result\n",
        "row_count = (len(data))\n",
        "run.log('observations', row_count)\n",
        "print('Analyzing {} rows of data'.format(row_count))\n",
        "\n",
        "# Plot and log the count of diabetic vs non-diabetic patients\n",
        "diabetic_counts = data['Diabetic'].value_counts()\n",
        "fig = plt.figure(figsize=(6,6))\n",
        "ax = fig.gca()    \n",
        "diabetic_counts.plot.bar(ax = ax) \n",
        "ax.set_title('Patients with Diabetes') \n",
        "ax.set_xlabel('Diagnosis') \n",
        "ax.set_ylabel('Patients')\n",
        "plt.show()\n",
        "run.log_image(name='label distribution', plot=fig)\n",
        "\n",
        "# log distinct pregnancy counts\n",
        "pregnancies = data.Pregnancies.unique()\n",
        "run.log_list('pregnancy categories', pregnancies)\n",
        "\n",
        "# Log summary statistics for numeric columns\n",
        "med_columns = ['PlasmaGlucose', 'DiastolicBloodPressure', 'TricepsThickness', 'SerumInsulin', 'BMI']\n",
        "summary_stats = data[med_columns].describe().to_dict()\n",
        "for col in summary_stats:\n",
        "    keys = list(summary_stats[col].keys())\n",
        "    values = list(summary_stats[col].values())\n",
        "    for index in range(len(keys)):\n",
        "        run.log_row(col, stat=keys[index], value = values[index])\n",
        "        \n",
        "# Save a sample of the data and upload it to the experiment output\n",
        "data.sample(100).to_csv('sample.csv', index=False, header=True)\n",
        "run.upload_file(name='outputs/sample.csv', path_or_stream='./sample.csv')\n",
        "\n",
        "# Complete the run\n",
        "run.complete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View run details\n",
        "\n",
        "In Jupyter Notebooks, you can use the **RunDetails** widget to see a visualization of the run details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1649363626246
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f05d80acf2b4a51986f42c6ddd89bd4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/e9a211fe-2cf5-43b0-beb8-b1cc4688cdf9?wsid=/subscriptions/73711bf5-4cda-4aca-893d-7e16cea46e36/resourcegroups/dp100/workspaces/dp100_mlws&tid=e714ef31-faab-41d2-9f1e-e6df4af16ab8\", \"run_id\": \"e9a211fe-2cf5-43b0-beb8-b1cc4688cdf9\", \"run_properties\": {\"run_id\": \"e9a211fe-2cf5-43b0-beb8-b1cc4688cdf9\", \"created_utc\": \"2022-06-09T22:15:16.022264Z\", \"properties\": {\"azureml.git.repository_uri\": \"https://github.com/arpan-ta/mslearn-dp100.git\", \"mlflow.source.git.repoURL\": \"https://github.com/arpan-ta/mslearn-dp100.git\", \"azureml.git.branch\": \"main\", \"mlflow.source.git.branch\": \"main\", \"azureml.git.commit\": \"d2354e40eec31c22eb09381c6a890311cccc30c9\", \"mlflow.source.git.commit\": \"d2354e40eec31c22eb09381c6a890311cccc30c9\", \"azureml.git.dirty\": \"True\", \"ContentSnapshotId\": \"0f95ee21-f7d6-42f7-b38e-a97ea7c8b239\"}, \"tags\": {}, \"end_time_utc\": \"2022-06-09T22:15:32.929161Z\", \"status\": \"Completed\", \"log_files\": {}, \"log_groups\": [], \"run_duration\": \"0:00:16\", \"run_number\": \"1654812916\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"observations\", \"run_id\": \"e9a211fe-2cf5-43b0-beb8-b1cc4688cdf9\", \"categories\": [0], \"series\": [{\"data\": [10000]}]}, {\"name\": \"label distribution\", \"run_id\": \"e9a211fe-2cf5-43b0-beb8-b1cc4688cdf9\", \"categories\": [0], \"series\": [{\"data\": [\"aml://artifactId/ExperimentRun/dcid.e9a211fe-2cf5-43b0-beb8-b1cc4688cdf9/label distribution_1654812925.png\"]}]}, {\"name\": \"pregnancy categories\", \"run_id\": \"e9a211fe-2cf5-43b0-beb8-b1cc4688cdf9\", \"categories\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], \"series\": [{\"data\": [0, 8, 7, 9, 1, 3, 5, 2, 6, 11, 4, 13, 10, 12, 14]}]}, {\"name\": \"PlasmaGlucose\", \"run_id\": \"e9a211fe-2cf5-43b0-beb8-b1cc4688cdf9\", \"categories\": [0], \"series\": [{\"data\": [{\"stat\": [\"count\", \"mean\", \"std\", \"min\", \"25%\", \"50%\", \"75%\", \"max\"], \"value\": [10000.0, 107.8502, 31.920909360565563, 44.0, 84.0, 105.0, 129.0, 192.0]}]}]}, {\"name\": \"DiastolicBloodPressure\", \"run_id\": \"e9a211fe-2cf5-43b0-beb8-b1cc4688cdf9\", \"categories\": [0], \"series\": [{\"data\": [{\"stat\": [\"count\", \"mean\", \"std\", \"min\", \"25%\", \"50%\", \"75%\", \"max\"], \"value\": [10000.0, 71.2075, 16.801478289640706, 24.0, 58.0, 72.0, 85.0, 117.0]}]}]}, {\"name\": \"TricepsThickness\", \"run_id\": \"e9a211fe-2cf5-43b0-beb8-b1cc4688cdf9\", \"categories\": [0], \"series\": [{\"data\": [{\"stat\": [\"count\", \"mean\", \"std\", \"min\", \"25%\", \"50%\", \"75%\", \"max\"], \"value\": [10000.0, 28.8176, 14.506480415228332, 7.0, 15.0, 31.0, 41.0, 92.0]}]}]}, {\"name\": \"SerumInsulin\", \"run_id\": \"e9a211fe-2cf5-43b0-beb8-b1cc4688cdf9\", \"categories\": [0], \"series\": [{\"data\": [{\"stat\": [\"count\", \"mean\", \"std\", \"min\", \"25%\", \"50%\", \"75%\", \"max\"], \"value\": [10000.0, 139.2436, 133.77791937465278, 14.0, 39.0, 85.0, 197.0, 796.0]}]}]}, {\"name\": \"BMI\", \"run_id\": \"e9a211fe-2cf5-43b0-beb8-b1cc4688cdf9\", \"categories\": [0], \"series\": [{\"data\": [{\"stat\": [\"count\", \"mean\", \"std\", \"min\", \"25%\", \"50%\", \"75%\", \"max\"], \"value\": [10000.0, 31.56702174359113, 9.804365693559113, 18.20080735, 21.247426835, 31.922420785, 39.3289214475, 56.03462763]}]}]}], \"run_logs\": \"\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.41.0\"}, \"loading\": false}"
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from azureml.widgets import RunDetails\n",
        "\n",
        "RunDetails(run).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### View more details in Azure Machine Learning studio\n",
        "\n",
        "Note that the **RunDetails** widget includes a link to **view run details** in Azure Machine Learning studio. Click this to open a new browser tab with the run details (you can also just open [Azure Machine Learning studio](https://ml.azure.com) and find the run on the **Experiments** page). When viewing the run in Azure Machine Learning studio, note the following:\n",
        "\n",
        "- The **Details** tab contains the general properties of the experiment run.\n",
        "- The **Metrics** tab enables you to select logged metrics and view them as tables or charts.\n",
        "- The **Images** tab enables you to select and view any images or plots that were logged in the experiment (in this case, the *Label Distribution* plot)\n",
        "- The **Child Runs** tab lists any child runs (in this experiment there are none).\n",
        "- The **Outputs + Logs** tab shows the output or log files generated by the experiment.\n",
        "- The **Snapshot** tab contains all files in the folder where the experiment code was run (in this case, everything in the same folder as this notebook).\n",
        "- The **Explanations** tab is used to show model explanations generated by the experiment (in this case, there are none).\n",
        "- The **Fairness** tab is used to visualize predictive performance disparities that help you evaluate the fairness of machine learning models (in this case, there are none)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Experiment,Run\n",
        "exp = Experiment(ws,\"mslearn-diabetes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "runs = exp.get_runs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "run = next(runs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>mslearn-diabetes</td><td>e9a211fe-2cf5-43b0-beb8-b1cc4688cdf9</td><td></td><td>Completed</td><td><a href=\"https://ml.azure.com/runs/e9a211fe-2cf5-43b0-beb8-b1cc4688cdf9?wsid=/subscriptions/73711bf5-4cda-4aca-893d-7e16cea46e36/resourcegroups/dp100/workspaces/dp100_mlws&amp;tid=e714ef31-faab-41d2-9f1e-e6df4af16ab8\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
            ],
            "text/plain": [
              "Run(Experiment: mslearn-diabetes,\n",
              "Id: e9a211fe-2cf5-43b0-beb8-b1cc4688cdf9,\n",
              "Type: None,\n",
              "Status: Completed)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Retrieve experiment details using the SDK\n",
        "\n",
        "The **run** variable in the code you ran previously is an instance of a **Run** object, which is a reference to an individual run of an experiment in Azure Machine Learning. You can use this reference to get information about the run and its outputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1649363632957
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics:\n",
            "observations : 10000\n",
            "label distribution : aml://artifactId/ExperimentRun/dcid.e9a211fe-2cf5-43b0-beb8-b1cc4688cdf9/label distribution_1654812925.png\n",
            "pregnancy categories : [0, 8, 7, 9, 1, 3, 5, 2, 6, 11, 4, 13, 10, 12, 14]\n",
            "PlasmaGlucose : {'stat': ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], 'value': [10000.0, 107.8502, 31.920909360565563, 44.0, 84.0, 105.0, 129.0, 192.0]}\n",
            "DiastolicBloodPressure : {'stat': ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], 'value': [10000.0, 71.2075, 16.801478289640706, 24.0, 58.0, 72.0, 85.0, 117.0]}\n",
            "TricepsThickness : {'stat': ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], 'value': [10000.0, 28.8176, 14.506480415228332, 7.0, 15.0, 31.0, 41.0, 92.0]}\n",
            "SerumInsulin : {'stat': ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], 'value': [10000.0, 139.2436, 133.77791937465278, 14.0, 39.0, 85.0, 197.0, 796.0]}\n",
            "BMI : {'stat': ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], 'value': [10000.0, 31.56702174359113, 9.804365693559113, 18.20080735, 21.247426835, 31.922420785, 39.3289214475, 56.03462763]}\n",
            "\n",
            "Files:\n",
            "label distribution_1654812925.png\n",
            "outputs/sample.csv\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Get logged metrics\n",
        "print(\"Metrics:\")\n",
        "metrics = run.get_metrics()\n",
        "for metric_name in metrics:\n",
        "    print(metric_name, \":\", metrics[metric_name])\n",
        "\n",
        "# Get output files\n",
        "print(\"\\nFiles:\")\n",
        "files = run.get_file_names()\n",
        "for file in files:\n",
        "    print(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can download the files produced by the experiment, either individually by using the **download_file** method, or by using the **download_files** method to retrieve multiple files. The following code downloads all of the files in the run's **output** folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1649363635892
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "downloaded-files/outputs/sample.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "download_folder = 'downloaded-files'\n",
        "\n",
        "# Download files in the \"outputs\" folder\n",
        "run.download_files(prefix='outputs', output_directory=download_folder)\n",
        "\n",
        "# Verify the files have been downloaded\n",
        "for root, directories, filenames in os.walk(download_folder): \n",
        "    for filename in filenames:  \n",
        "        print (os.path.join(root,filename))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you need to troubleshoot the experiment run, you can use the **get_details** method to retrieve basic details about the run, or you can use the **get_details_with_logs** method to retrieve the run details as well as the contents of log files generated during the run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1649363638967
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'runId': 'e9a211fe-2cf5-43b0-beb8-b1cc4688cdf9',\n",
              " 'target': 'local',\n",
              " 'status': 'Completed',\n",
              " 'startTimeUtc': '2022-06-09T22:15:16.41436Z',\n",
              " 'endTimeUtc': '2022-06-09T22:15:32.929161Z',\n",
              " 'services': {},\n",
              " 'properties': {'azureml.git.repository_uri': 'https://github.com/arpan-ta/mslearn-dp100.git',\n",
              "  'mlflow.source.git.repoURL': 'https://github.com/arpan-ta/mslearn-dp100.git',\n",
              "  'azureml.git.branch': 'main',\n",
              "  'mlflow.source.git.branch': 'main',\n",
              "  'azureml.git.commit': 'd2354e40eec31c22eb09381c6a890311cccc30c9',\n",
              "  'mlflow.source.git.commit': 'd2354e40eec31c22eb09381c6a890311cccc30c9',\n",
              "  'azureml.git.dirty': 'True',\n",
              "  'ContentSnapshotId': '0f95ee21-f7d6-42f7-b38e-a97ea7c8b239'},\n",
              " 'inputDatasets': [],\n",
              " 'outputDatasets': [],\n",
              " 'logFiles': {},\n",
              " 'submittedBy': 'Arpan Venugopal'}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run.get_details_with_logs()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that the details include information about the compute target on which the experiment was run, the date and time when it started and ended. Additionally, because the notebook containing the experiment code (this one) is in a cloned Git repository, details about the repo, branch, and status are recorded in the run history.\n",
        "\n",
        "In this case, note that the **logFiles** entry in the details indicates that no log files were generated. That's typical for an inline experiment like the one you ran, but things get more interesting when you run a script as an experiment; which is what we'll look at next."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run an experiment script\n",
        "\n",
        "In the previous example, you ran an experiment inline in this notebook. A more flexible solution is to create a separate script for the experiment, and store it in a folder along with any other files it needs, and then use Azure ML to run the experiment based on the script in the folder.\n",
        "\n",
        "First, let's create a folder for the experiment files, and copy the data into it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1649363641423
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'diabetes-experiment-files/diabetes.csv'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os, shutil\n",
        "\n",
        "# Create a folder for the experiment files\n",
        "folder_name = 'diabetes-experiment-files'\n",
        "experiment_folder = './' + folder_name\n",
        "os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "# Copy the data file into the experiment folder\n",
        "shutil.copy('data/diabetes.csv', os.path.join(folder_name, \"diabetes.csv\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we'll create a Python script containing the code for our experiment, and save it in the experiment folder.\n",
        "\n",
        "> **Note**: running the following cell just *creates* the script file - it doesn't run it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing diabetes-experiment-files/diabetes_experiment.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile $folder_name/diabetes_experiment.py\n",
        "from azureml.core import Run\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the diabetes dataset\n",
        "data = pd.read_csv('diabetes.csv')\n",
        "\n",
        "# Count the rows and log the result\n",
        "row_count = (len(data))\n",
        "run.log('observations', row_count)\n",
        "print('Analyzing {} rows of data'.format(row_count))\n",
        "\n",
        "# Count and log the label counts\n",
        "diabetic_counts = data['Diabetic'].value_counts()\n",
        "print(diabetic_counts)\n",
        "for k, v in diabetic_counts.items():\n",
        "    run.log('Label:' + str(k), v)\n",
        "      \n",
        "# Save a sample of the data in the outputs folder (which gets uploaded automatically)\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "data.sample(100).to_csv(\"outputs/sample.csv\", index=False, header=True)\n",
        "\n",
        "# Complete the run\n",
        "run.complete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This code is a simplified version of the inline code used before. However, note the following:\n",
        "- It uses the `Run.get_context()` method to retrieve the experiment run context when the script is run.\n",
        "- It loads the diabetes data from the folder where the script is located.\n",
        "- It creates a folder named **outputs** and writes the sample file to it - this folder is automatically uploaded to the experiment run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now you're almost ready to run the experiment. To run the script, you must create a **ScriptRunConfig** that identifies the Python script file to be run in the experiment, and then run an experiment based on it.\n",
        "\n",
        "> **Note**: The ScriptRunConfig also determines the compute target and Python environment. In this case, the Python environment is defined to include some Conda and pip packages, but the compute target is omitted; so the default local compute will be used.\n",
        "\n",
        "The following cell configures and submits the script-based experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1649363661425
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1d716be27484cafaf8dba91aabd597e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/mslearn-diabetes_1654815067_d3e584ca?wsid=/subscriptions/73711bf5-4cda-4aca-893d-7e16cea46e36/resourcegroups/dp100/workspaces/dp100_mlws&tid=e714ef31-faab-41d2-9f1e-e6df4af16ab8\", \"run_id\": \"mslearn-diabetes_1654815067_d3e584ca\", \"run_properties\": {\"run_id\": \"mslearn-diabetes_1654815067_d3e584ca\", \"created_utc\": \"2022-06-09T22:51:08.528468Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"7d853180-84b7-46da-9b2b-e656a4d5ca81\", \"azureml.git.repository_uri\": \"https://github.com/arpan-ta/mslearn-dp100.git\", \"mlflow.source.git.repoURL\": \"https://github.com/arpan-ta/mslearn-dp100.git\", \"azureml.git.branch\": \"main\", \"mlflow.source.git.branch\": \"main\", \"azureml.git.commit\": \"d2354e40eec31c22eb09381c6a890311cccc30c9\", \"mlflow.source.git.commit\": \"d2354e40eec31c22eb09381c6a890311cccc30c9\", \"azureml.git.dirty\": \"True\"}, \"tags\": {\"mlflow.source.type\": \"JOB\", \"mlflow.source.name\": \"diabetes_experiment.py\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2022-06-09T22:54:18.529229Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://dp100mlws7512094280.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes_1654815067_d3e584ca/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=sEkE7%2BwC4HKutPYMI4J2aGNFxYRLdPr2pCdGxddGmmg%3D&skoid=aa567b24-7487-4111-90c5-f77419aa7dff&sktid=e714ef31-faab-41d2-9f1e-e6df4af16ab8&skt=2022-06-09T22%3A05%3A26Z&ske=2022-06-11T06%3A15%3A26Z&sks=b&skv=2019-07-07&st=2022-06-09T22%3A59%3A52Z&se=2022-06-10T07%3A09%3A52Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://dp100mlws7512094280.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes_1654815067_d3e584ca/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=sJP4gpO70nZUAaG8Bm2lz1W%2BMHPwoSMoU6vndY%2B4lx8%3D&skoid=aa567b24-7487-4111-90c5-f77419aa7dff&sktid=e714ef31-faab-41d2-9f1e-e6df4af16ab8&skt=2022-06-09T22%3A05%3A26Z&ske=2022-06-11T06%3A15%3A26Z&sks=b&skv=2019-07-07&st=2022-06-09T22%3A59%3A52Z&se=2022-06-10T07%3A09%3A52Z&sp=r\", \"logs/azureml/8_azureml.log\": \"https://dp100mlws7512094280.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes_1654815067_d3e584ca/logs/azureml/8_azureml.log?sv=2019-07-07&sr=b&sig=FqfxNeoWzJyNm6iix%2FFUGA9%2ByZksNs6h%2BsSiNDvJ4ys%3D&skoid=aa567b24-7487-4111-90c5-f77419aa7dff&sktid=e714ef31-faab-41d2-9f1e-e6df4af16ab8&skt=2022-06-09T22%3A05%3A26Z&ske=2022-06-11T06%3A15%3A26Z&sks=b&skv=2019-07-07&st=2022-06-09T22%3A59%3A52Z&se=2022-06-10T07%3A09%3A52Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/8_azureml.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"]], \"run_duration\": \"0:03:10\", \"run_number\": \"1654815068\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"observations\", \"run_id\": \"mslearn-diabetes_1654815067_d3e584ca\", \"categories\": [0], \"series\": [{\"data\": [10000]}]}, {\"name\": \"Label:0\", \"run_id\": \"mslearn-diabetes_1654815067_d3e584ca\", \"categories\": [0], \"series\": [{\"data\": [6656]}]}, {\"name\": \"Label:1\", \"run_id\": \"mslearn-diabetes_1654815067_d3e584ca\", \"categories\": [0], \"series\": [{\"data\": [3344]}]}], \"run_logs\": \"[2022-06-09T22:54:07.886922] Entering context manager injector.\\nCannot provide tracer without any exporter configured.\\n[2022-06-09T22:54:08.507023] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['diabetes_experiment.py'])\\nScript type = None\\n[2022-06-09T22:54:08.510221] Entering Run History Context Manager.\\n/azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib/python3.6/site-packages/azureml/history/_tracking.py:186: FutureWarning: MLflow support for Python 3.6 is deprecated and will be dropped in an upcoming release. At that point, existing Python 3.6 workflows that use MLflow will continue to work without modification, but Python 3.6 users will no longer get access to the latest MLflow features and bugfixes. We recommend that you upgrade to Python 3.7 or newer.\\n  import mlflow\\n[2022-06-09T22:54:10.744540] Current directory: /azureml-run\\n[2022-06-09T22:54:10.744568] Preparing to call script [diabetes_experiment.py] with arguments:[]\\n[2022-06-09T22:54:10.744586] After variable expansion, calling script [diabetes_experiment.py] with arguments:[]\\n\\nAnalyzing 10000 rows of data\\n0    6656\\n1    3344\\nName: Diabetic, dtype: int64\\n\\n\\n[2022-06-09T22:54:16.288694] The experiment completed successfully. Finalizing run...\\n[2022-06-09T22:54:16.288721] Start FinalizingInRunHistory\\n[2022-06-09T22:54:16.290856] Logging experiment finalizing status in history service.\\nStarting the daemon thread to refresh tokens in background for process with pid = 8\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\n2 items cleaning up...\\nCleanup took 0.10537052154541016 seconds\\n[2022-06-09T22:54:17.298168] Finished context manager injector.\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.41.0\"}, \"loading\": false}"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'runId': 'mslearn-diabetes_1654815067_d3e584ca',\n",
              " 'target': 'local',\n",
              " 'status': 'Completed',\n",
              " 'startTimeUtc': '2022-06-09T22:54:07.042374Z',\n",
              " 'endTimeUtc': '2022-06-09T22:54:18.529229Z',\n",
              " 'services': {},\n",
              " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
              "  'ContentSnapshotId': '7d853180-84b7-46da-9b2b-e656a4d5ca81',\n",
              "  'azureml.git.repository_uri': 'https://github.com/arpan-ta/mslearn-dp100.git',\n",
              "  'mlflow.source.git.repoURL': 'https://github.com/arpan-ta/mslearn-dp100.git',\n",
              "  'azureml.git.branch': 'main',\n",
              "  'mlflow.source.git.branch': 'main',\n",
              "  'azureml.git.commit': 'd2354e40eec31c22eb09381c6a890311cccc30c9',\n",
              "  'mlflow.source.git.commit': 'd2354e40eec31c22eb09381c6a890311cccc30c9',\n",
              "  'azureml.git.dirty': 'True'},\n",
              " 'inputDatasets': [],\n",
              " 'outputDatasets': [],\n",
              " 'runDefinition': {'script': 'diabetes_experiment.py',\n",
              "  'command': '',\n",
              "  'useAbsolutePath': False,\n",
              "  'arguments': [],\n",
              "  'sourceDirectoryDataStore': None,\n",
              "  'framework': 'Python',\n",
              "  'communicator': 'None',\n",
              "  'target': 'local',\n",
              "  'dataReferences': {},\n",
              "  'data': {},\n",
              "  'outputData': {},\n",
              "  'datacaches': [],\n",
              "  'jobName': None,\n",
              "  'maxRunDurationSeconds': 2592000,\n",
              "  'nodeCount': 1,\n",
              "  'instanceTypes': [],\n",
              "  'priority': None,\n",
              "  'credentialPassthrough': False,\n",
              "  'identity': None,\n",
              "  'environment': {'name': 'experiment_env',\n",
              "   'version': 'Autosave_2022-06-09T22:51:08Z_fa73d59d',\n",
              "   'python': {'interpreterPath': 'python',\n",
              "    'userManagedDependencies': False,\n",
              "    'condaDependencies': {'dependencies': ['python=3.6.2',\n",
              "      'scikit-learn',\n",
              "      'pandas',\n",
              "      'pip',\n",
              "      {'pip': ['azureml-defaults', 'azureml-mlflow']}],\n",
              "     'name': 'simple_environment'},\n",
              "    'baseCondaEnvironment': None},\n",
              "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
              "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220412.v1',\n",
              "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
              "    'baseDockerfile': None,\n",
              "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
              "    'enabled': False,\n",
              "    'arguments': []},\n",
              "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
              "   'inferencingStackVersion': None},\n",
              "  'history': {'outputCollection': True,\n",
              "   'directoriesToWatch': ['logs'],\n",
              "   'enableMLflowTracking': True,\n",
              "   'snapshotProject': True},\n",
              "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
              "    'spark.yarn.maxAppAttempts': '1'}},\n",
              "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
              "   'workerCountPerNode': 1,\n",
              "   'terminalExitCodes': None,\n",
              "   'configuration': {}},\n",
              "  'amlCompute': {'name': None,\n",
              "   'vmSize': None,\n",
              "   'retainCluster': False,\n",
              "   'clusterMaxNodeCount': None},\n",
              "  'aiSuperComputer': {'instanceType': 'D2',\n",
              "   'imageVersion': 'pytorch-1.7.0',\n",
              "   'location': None,\n",
              "   'aiSuperComputerStorageData': None,\n",
              "   'interactive': False,\n",
              "   'scalePolicy': None,\n",
              "   'virtualClusterArmId': None,\n",
              "   'tensorboardLogDirectory': None,\n",
              "   'sshPublicKey': None,\n",
              "   'sshPublicKeys': None,\n",
              "   'enableAzmlInt': True,\n",
              "   'priority': 'Medium',\n",
              "   'slaTier': 'Standard',\n",
              "   'userAlias': None},\n",
              "  'kubernetesCompute': {'instanceType': None},\n",
              "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
              "  'mpi': {'processCountPerNode': 1},\n",
              "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
              "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
              "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
              "  'exposedPorts': None,\n",
              "  'docker': {'useDocker': True,\n",
              "   'sharedVolumes': True,\n",
              "   'shmSize': '2g',\n",
              "   'arguments': []},\n",
              "  'cmk8sCompute': {'configuration': {}},\n",
              "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
              "   'successfulReturnCodes': []},\n",
              "  'environmentVariables': {},\n",
              "  'applicationEndpoints': {},\n",
              "  'parameters': []},\n",
              " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://dp100mlws7512094280.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes_1654815067_d3e584ca/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=ss9%2FcjwDuiHz85vf5AvGz6BLQxKh9XU5Yb3ahTAozfw%3D&skoid=aa567b24-7487-4111-90c5-f77419aa7dff&sktid=e714ef31-faab-41d2-9f1e-e6df4af16ab8&skt=2022-06-09T22%3A05%3A26Z&ske=2022-06-11T06%3A15%3A26Z&sks=b&skv=2019-07-07&st=2022-06-09T22%3A44%3A20Z&se=2022-06-10T06%3A54%3A20Z&sp=r',\n",
              "  'azureml-logs/70_driver_log.txt': 'https://dp100mlws7512094280.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes_1654815067_d3e584ca/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=VtiUVUCsOegEinyQrDLzz%2BAy2v9QxAQ%2BL%2BEkuD6sTTY%3D&skoid=aa567b24-7487-4111-90c5-f77419aa7dff&sktid=e714ef31-faab-41d2-9f1e-e6df4af16ab8&skt=2022-06-09T22%3A05%3A26Z&ske=2022-06-11T06%3A15%3A26Z&sks=b&skv=2019-07-07&st=2022-06-09T22%3A44%3A20Z&se=2022-06-10T06%3A54%3A20Z&sp=r',\n",
              "  'logs/azureml/8_azureml.log': 'https://dp100mlws7512094280.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes_1654815067_d3e584ca/logs/azureml/8_azureml.log?sv=2019-07-07&sr=b&sig=wQK9iLbzxHAp4sXiIsSThXILfR1TW%2F19v%2Bq4QYBcNrU%3D&skoid=aa567b24-7487-4111-90c5-f77419aa7dff&sktid=e714ef31-faab-41d2-9f1e-e6df4af16ab8&skt=2022-06-09T22%3A05%3A26Z&ske=2022-06-11T06%3A15%3A26Z&sks=b&skv=2019-07-07&st=2022-06-09T22%3A44%3A11Z&se=2022-06-10T06%3A54%3A11Z&sp=r'},\n",
              " 'submittedBy': 'Arpan Venugopal'}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
        "from azureml.core.runconfig import DockerConfiguration\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Create a Python environment for the experiment (from a .yml file)\n",
        "env = Environment.from_conda_specification(\"experiment_env\", \"environment.yml\")\n",
        "\n",
        "# Create a script config\n",
        "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
        "                                script='diabetes_experiment.py',\n",
        "                                environment=env,\n",
        "                                docker_runtime_config=DockerConfiguration(use_docker=True))\n",
        "\n",
        "# submit the experiment\n",
        "experiment = Experiment(workspace=ws, name='mslearn-diabetes')\n",
        "run = experiment.submit(config=script_config)\n",
        "RunDetails(run).show()\n",
        "run.wait_for_completion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As before, you can use the widget or the link to the experiment in [Azure Machine Learning studio](https://ml.azure.com) to view the outputs generated by the experiment, and you can also write code to retrieve the metrics and files it generated:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1649363665408
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "observations 10000\n",
            "Label:0 6656\n",
            "Label:1 3344\n",
            "\n",
            "\n",
            "azureml-logs/60_control_log.txt\n",
            "azureml-logs/70_driver_log.txt\n",
            "logs/azureml/8_azureml.log\n",
            "outputs/sample.csv\n"
          ]
        }
      ],
      "source": [
        "# Get logged metrics\n",
        "metrics = run.get_metrics()\n",
        "for key in metrics.keys():\n",
        "        print(key, metrics.get(key))\n",
        "print('\\n')\n",
        "for file in run.get_file_names():\n",
        "    print(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that this time, the run generated some log files. You can view these in the widget, or you can use the **get_details_with_logs** method like we did before, only this time the output will include the log data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1649363668206
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'runId': 'mslearn-diabetes_1654815067_d3e584ca',\n",
              " 'target': 'local',\n",
              " 'status': 'Completed',\n",
              " 'startTimeUtc': '2022-06-09T22:54:07.042374Z',\n",
              " 'endTimeUtc': '2022-06-09T22:54:18.529229Z',\n",
              " 'services': {},\n",
              " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
              "  'ContentSnapshotId': '7d853180-84b7-46da-9b2b-e656a4d5ca81',\n",
              "  'azureml.git.repository_uri': 'https://github.com/arpan-ta/mslearn-dp100.git',\n",
              "  'mlflow.source.git.repoURL': 'https://github.com/arpan-ta/mslearn-dp100.git',\n",
              "  'azureml.git.branch': 'main',\n",
              "  'mlflow.source.git.branch': 'main',\n",
              "  'azureml.git.commit': 'd2354e40eec31c22eb09381c6a890311cccc30c9',\n",
              "  'mlflow.source.git.commit': 'd2354e40eec31c22eb09381c6a890311cccc30c9',\n",
              "  'azureml.git.dirty': 'True'},\n",
              " 'inputDatasets': [],\n",
              " 'outputDatasets': [],\n",
              " 'runDefinition': {'script': 'diabetes_experiment.py',\n",
              "  'command': '',\n",
              "  'useAbsolutePath': False,\n",
              "  'arguments': [],\n",
              "  'sourceDirectoryDataStore': None,\n",
              "  'framework': 'Python',\n",
              "  'communicator': 'None',\n",
              "  'target': 'local',\n",
              "  'dataReferences': {},\n",
              "  'data': {},\n",
              "  'outputData': {},\n",
              "  'datacaches': [],\n",
              "  'jobName': None,\n",
              "  'maxRunDurationSeconds': 2592000,\n",
              "  'nodeCount': 1,\n",
              "  'instanceTypes': [],\n",
              "  'priority': None,\n",
              "  'credentialPassthrough': False,\n",
              "  'identity': None,\n",
              "  'environment': {'name': 'experiment_env',\n",
              "   'version': 'Autosave_2022-06-09T22:51:08Z_fa73d59d',\n",
              "   'python': {'interpreterPath': 'python',\n",
              "    'userManagedDependencies': False,\n",
              "    'condaDependencies': {'dependencies': ['python=3.6.2',\n",
              "      'scikit-learn',\n",
              "      'pandas',\n",
              "      'pip',\n",
              "      {'pip': ['azureml-defaults', 'azureml-mlflow']}],\n",
              "     'name': 'simple_environment'},\n",
              "    'baseCondaEnvironment': None},\n",
              "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
              "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220412.v1',\n",
              "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
              "    'baseDockerfile': None,\n",
              "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
              "    'enabled': False,\n",
              "    'arguments': []},\n",
              "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
              "   'inferencingStackVersion': None},\n",
              "  'history': {'outputCollection': True,\n",
              "   'directoriesToWatch': ['logs'],\n",
              "   'enableMLflowTracking': True,\n",
              "   'snapshotProject': True},\n",
              "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
              "    'spark.yarn.maxAppAttempts': '1'}},\n",
              "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
              "   'workerCountPerNode': 1,\n",
              "   'terminalExitCodes': None,\n",
              "   'configuration': {}},\n",
              "  'amlCompute': {'name': None,\n",
              "   'vmSize': None,\n",
              "   'retainCluster': False,\n",
              "   'clusterMaxNodeCount': None},\n",
              "  'aiSuperComputer': {'instanceType': 'D2',\n",
              "   'imageVersion': 'pytorch-1.7.0',\n",
              "   'location': None,\n",
              "   'aiSuperComputerStorageData': None,\n",
              "   'interactive': False,\n",
              "   'scalePolicy': None,\n",
              "   'virtualClusterArmId': None,\n",
              "   'tensorboardLogDirectory': None,\n",
              "   'sshPublicKey': None,\n",
              "   'sshPublicKeys': None,\n",
              "   'enableAzmlInt': True,\n",
              "   'priority': 'Medium',\n",
              "   'slaTier': 'Standard',\n",
              "   'userAlias': None},\n",
              "  'kubernetesCompute': {'instanceType': None},\n",
              "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
              "  'mpi': {'processCountPerNode': 1},\n",
              "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
              "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
              "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
              "  'exposedPorts': None,\n",
              "  'docker': {'useDocker': True,\n",
              "   'sharedVolumes': True,\n",
              "   'shmSize': '2g',\n",
              "   'arguments': []},\n",
              "  'cmk8sCompute': {'configuration': {}},\n",
              "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
              "   'successfulReturnCodes': []},\n",
              "  'environmentVariables': {},\n",
              "  'applicationEndpoints': {},\n",
              "  'parameters': []},\n",
              " 'logFiles': {'azureml-logs/60_control_log.txt': '[2022-06-09T22:51:09.107572] Using urllib.request Python 3.0 or later\\nStreaming log file azureml-logs/60_control_log.txt\\nStarting the daemon thread to refresh tokens in background for process with pid = 12012\\nRunning: [\\'/bin/bash\\', \\'/tmp/azureml_runs/mslearn-diabetes_1654815067_d3e584ca/azureml-environment-setup/docker_env_checker.sh\\']\\n\\nMaterialized image not found on target: azureml/azureml_69e2aae1dd257f36fb2e15140cb037e9\\n\\n\\n[2022-06-09T22:51:12.488103] Logging experiment preparation status in history service.\\nRunning: [\\'/bin/bash\\', \\'/tmp/azureml_runs/mslearn-diabetes_1654815067_d3e584ca/azureml-environment-setup/docker_env_builder.sh\\']\\nRunning: [\\'nvidia-docker\\', \\'build\\', \\'-f\\', \\'azureml-environment-setup/Dockerfile\\', \\'-t\\', \\'azureml/azureml_69e2aae1dd257f36fb2e15140cb037e9\\', \\'.\\']\\nSending build context to Docker daemon  1.114MB\\nStep 1/17 : FROM mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220412.v1@sha256:7b2748bbf455a2d5adc8dd5af3c5c7890a23ef8336458251b6ebd5093f91eca0\\nmcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220412.v1@sha256:7b2748bbf455a2d5adc8dd5af3c5c7890a23ef8336458251b6ebd5093f91eca0: Pulling from azureml/openmpi3.1.2-ubuntu18.04\\n08a6abff8943: Pulling fs layer\\n3fc933ffb1b7: Pulling fs layer\\nac93e58c5dc7: Pulling fs layer\\n5dcdef402503: Pulling fs layer\\nbbf579d09b2f: Pulling fs layer\\n4561d7db36b6: Pulling fs layer\\nd112deec94d8: Pulling fs layer\\nf8fe34184935: Pulling fs layer\\n805a516c439d: Pulling fs layer\\n4561d7db36b6: Waiting\\nd112deec94d8: Waiting\\n5dcdef402503: Waiting\\nf8fe34184935: Waiting\\nbbf579d09b2f: Waiting\\n805a516c439d: Waiting\\n08a6abff8943: Verifying Checksum\\n08a6abff8943: Download complete\\nac93e58c5dc7: Verifying Checksum\\nac93e58c5dc7: Download complete\\n5dcdef402503: Verifying Checksum\\n5dcdef402503: Download complete\\nbbf579d09b2f: Verifying Checksum\\nbbf579d09b2f: Download complete\\nd112deec94d8: Verifying Checksum\\nd112deec94d8: Download complete\\n4561d7db36b6: Verifying Checksum\\n4561d7db36b6: Download complete\\nf8fe34184935: Verifying Checksum\\nf8fe34184935: Download complete\\n805a516c439d: Verifying Checksum\\n805a516c439d: Download complete\\n3fc933ffb1b7: Verifying Checksum\\n3fc933ffb1b7: Download complete\\n08a6abff8943: Pull complete\\n3fc933ffb1b7: Pull complete\\nac93e58c5dc7: Pull complete\\n5dcdef402503: Pull complete\\nbbf579d09b2f: Pull complete\\n4561d7db36b6: Pull complete\\nd112deec94d8: Pull complete\\nf8fe34184935: Pull complete\\n805a516c439d: Pull complete\\nDigest: sha256:7b2748bbf455a2d5adc8dd5af3c5c7890a23ef8336458251b6ebd5093f91eca0\\nStatus: Downloaded newer image for mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220412.v1@sha256:7b2748bbf455a2d5adc8dd5af3c5c7890a23ef8336458251b6ebd5093f91eca0\\n ---> b2db557fb48e\\nStep 2/17 : USER root\\n ---> Running in b841f3db9daf\\nRemoving intermediate container b841f3db9daf\\n ---> 2d6176737942\\nStep 3/17 : RUN mkdir -p $HOME/.cache\\n ---> Running in 3daa1a0acd5f\\nRemoving intermediate container 3daa1a0acd5f\\n ---> 2007d378e42d\\nStep 4/17 : WORKDIR /\\n ---> Running in 8b7387ff2e14\\nRemoving intermediate container 8b7387ff2e14\\n ---> e6cd6b4ed697\\nStep 5/17 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\\n ---> d23bf867b3d4\\nStep 6/17 : RUN if dpkg --compare-versions `conda --version | grep -oE \\'[^ ]+$\\'` lt 4.4.11; then conda install conda==4.4.11; fi\\n ---> Running in 7a0cdee47ade\\nRemoving intermediate container 7a0cdee47ade\\n ---> 690969a9158f\\nStep 7/17 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\\n ---> a336ae01eec1\\nStep 8/17 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\\n ---> Running in 1a71244fe4b9\\nCollecting package metadata (repodata.json): ...working... done\\nSolving environment: ...working... done\\n\\nDownloading and Extracting Packages\\nopenssl-1.0.2u       | 2.2 MB    | ########## | 100% \\nsqlite-3.23.1        | 808 KB    | ########## | 100% \\nsix-1.16.0           | 18 KB     | ########## | 100% \\nlibffi-3.2.1         | 48 KB     | ########## | 100% \\nscipy-1.5.2          | 14.4 MB   | ########## | 100% \\nsetuptools-58.0.4    | 788 KB    | ########## | 100% \\nnumpy-1.19.2         | 22 KB     | ########## | 100% \\nwheel-0.37.1         | 33 KB     | ########## | 100% \\ntk-8.6.12            | 3.0 MB    | ########## | 100% \\n_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \\nzlib-1.2.12          | 106 KB    | ########## | 100% \\nlibedit-3.1          | 151 KB    | ########## | 100% \\nlibgomp-11.2.0       | 474 KB    | ########## | 100% \\n_openmp_mutex-5.1    | 21 KB     | ########## | 100% \\ncertifi-2021.5.30    | 139 KB    | ########## | 100% \\nintel-openmp-2022.0. | 4.2 MB    | ########## | 100% \\nmkl_fft-1.3.0        | 170 KB    | ########## | 100% \\nmkl-service-2.3.0    | 52 KB     | ########## | 100% \\npython-dateutil-2.8. | 233 KB    | ########## | 100% \\nca-certificates-2022 | 124 KB    | ########## | 100% \\nmkl_random-1.1.1     | 327 KB    | ########## | 100% \\nlibstdcxx-ng-11.2.0  | 4.7 MB    | ########## | 100% \\nxz-5.2.5             | 339 KB    | ########## | 100% \\npython-3.6.2         | 23.6 MB   | ########## | 100% \\npytz-2021.3          | 171 KB    | ########## | 100% \\nnumpy-base-1.19.2    | 4.1 MB    | ########## | 100% \\nreadline-7.0         | 848 KB    | ########## | 100% \\njoblib-1.0.1         | 208 KB    | ########## | 100% \\npandas-1.1.5         | 8.2 MB    | ########## | 100% \\nlibgfortran-ng-7.5.0 | 22 KB     | ########## | 100% \\nlibgfortran4-7.5.0   | 995 KB    | ########## | 100% \\nncurses-6.0          | 781 KB    | ########## | 100% \\nthreadpoolctl-2.2.0  | 16 KB     | ########## | 100% \\nlibgcc-ng-11.2.0     | 5.3 MB    | ########## | 100% \\nmkl-2020.2           | 138.3 MB  | ########## | 100% \\nscikit-learn-0.24.2  | 5.2 MB    | ########## | 100% \\npip-21.2.2           | 1.8 MB    | ########## | 100% \\nblas-1.0             | 6 KB      | ########## | 100% \\nPreparing transaction: ...working... done\\nVerifying transaction: ...working... done\\nExecuting transaction: ...working... \\n\\n    Installed package of scikit-learn can be accelerated using scikit-learn-intelex.\\n    More details are available here: https://intel.github.io/scikit-learn-intelex\\n\\n    For example:\\n\\n        $ conda install scikit-learn-intelex\\n        $ python -m sklearnex my_application.py\\n\\n    \\n\\ndone\\nInstalling pip dependencies: ...working... Ran pip subprocess with arguments:\\n[\\'/azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/bin/python\\', \\'-m\\', \\'pip\\', \\'install\\', \\'-U\\', \\'-r\\', \\'/azureml-environment-setup/condaenv.pqz36maz.requirements.txt\\']\\nPip subprocess output:\\nCollecting azureml-defaults\\n  Downloading azureml_defaults-1.42.0-py3-none-any.whl (2.0 kB)\\nCollecting azureml-mlflow\\n  Downloading azureml_mlflow-1.42.0-py3-none-any.whl (50 kB)\\nCollecting azureml-core~=1.42.0\\n  Downloading azureml_core-1.42.0.post1-py3-none-any.whl (2.7 MB)\\nCollecting azureml-dataset-runtime[fuse]~=1.42.0\\n  Downloading azureml_dataset_runtime-1.42.0-py3-none-any.whl (2.2 kB)\\nCollecting json-logging-py==0.2\\n  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\\nCollecting configparser==3.7.4\\n  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\\nCollecting azureml-inference-server-http~=0.4.1\\n  Downloading azureml_inference_server_http-0.4.13-py3-none-any.whl (39 kB)\\nCollecting jsonpickle\\n  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\\nCollecting mlflow-skinny\\n  Downloading mlflow_skinny-1.23.1-py3-none-any.whl (3.2 MB)\\nRequirement already satisfied: pytz in /azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib/python3.6/site-packages (from azureml-core~=1.42.0->azureml-defaults->-r /azureml-environment-setup/condaenv.pqz36maz.requirements.txt (line 1)) (2021.3)\\nCollecting azure-mgmt-keyvault<10.0.0,>=0.40.0\\n  Downloading azure_mgmt_keyvault-9.3.0-py2.py3-none-any.whl (412 kB)\\nCollecting paramiko<3.0.0,>=2.0.8\\n  Downloading paramiko-2.11.0-py2.py3-none-any.whl (212 kB)\\nCollecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<37.0.0\\n  Downloading cryptography-36.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\\nCollecting SecretStorage<4.0.0\\n  Downloading SecretStorage-3.3.2-py3-none-any.whl (15 kB)\\nCollecting azure-mgmt-storage<=20.0.0,>=16.0.0\\n  Downloading azure_mgmt_storage-20.0.0-py3-none-any.whl (2.0 MB)\\nCollecting msrestazure<=0.6.4,>=0.4.33\\n  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\\nCollecting pyopenssl<23.0.0\\n  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\\nCollecting azure-graphrbac<1.0.0,>=0.40.0\\n  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\\nCollecting humanfriendly<11.0,>=4.7\\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\\nCollecting ndg-httpsclient<=0.5.1\\n  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\\nCollecting adal<=1.2.7,>=1.2.0\\n  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\\nCollecting pkginfo\\n  Downloading pkginfo-1.8.3-py2.py3-none-any.whl (26 kB)\\nCollecting jmespath<=1.0.0\\n  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\\nCollecting knack~=0.9.0\\n  Downloading knack-0.9.0-py3-none-any.whl (59 kB)\\nCollecting azure-mgmt-resource<=21.0.0,>=15.0.0\\n  Downloading azure_mgmt_resource-21.0.0-py3-none-any.whl (2.3 MB)\\nCollecting azure-common<2.0.0,>=1.1.12\\n  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\\nCollecting azure-mgmt-containerregistry<10,>=8.2.0\\n  Downloading azure_mgmt_containerregistry-9.1.0-py3-none-any.whl (1.1 MB)\\nCollecting pathspec<1.0.0\\n  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\\nCollecting packaging<22.0,>=20.0\\n  Downloading packaging-21.3-py3-none-any.whl (40 kB)\\nCollecting msrest<0.7.0,>=0.5.1\\n  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\\nRequirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib/python3.6/site-packages (from azureml-core~=1.42.0->azureml-defaults->-r /azureml-environment-setup/condaenv.pqz36maz.requirements.txt (line 1)) (2.8.2)\\nCollecting requests[socks]<3.0.0,>=2.19.1\\n  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\\nCollecting PyJWT<3.0.0\\n  Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB)\\nCollecting msal<2.0.0,>=1.15.0\\n  Downloading msal-1.18.0-py2.py3-none-any.whl (82 kB)\\nCollecting azure-core<=1.22.1\\n  Downloading azure_core-1.22.1-py3-none-any.whl (178 kB)\\nCollecting docker<6.0.0\\n  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\\nCollecting urllib3<=1.26.9,>=1.23\\n  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\\nCollecting argcomplete<3\\n  Downloading argcomplete-2.0.0-py2.py3-none-any.whl (37 kB)\\nCollecting backports.tempfile\\n  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\\nCollecting azure-mgmt-authorization<3,>=0.40.0\\n  Downloading azure_mgmt_authorization-2.0.0-py2.py3-none-any.whl (465 kB)\\nCollecting contextlib2<22.0.0\\n  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\\nCollecting msal-extensions<=1.0.0,>=0.3.0\\n  Downloading msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB)\\nCollecting importlib-metadata<5,>=0.23\\n  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\\nRequirement already satisfied: six>=1.11.0 in /azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib/python3.6/site-packages (from azure-core<=1.22.1->azureml-core~=1.42.0->azureml-defaults->-r /azureml-environment-setup/condaenv.pqz36maz.requirements.txt (line 1)) (1.16.0)\\nCollecting azure-mgmt-core<2.0.0,>=1.2.0\\n  Downloading azure_mgmt_core-1.3.0-py2.py3-none-any.whl (25 kB)\\nCollecting pyarrow<4.0.0,>=0.17.0\\n  Downloading pyarrow-3.0.0-cp36-cp36m-manylinux2014_x86_64.whl (20.7 MB)\\nCollecting azureml-dataprep<4.1.0a,>=4.0.0a\\n  Downloading azureml_dataprep-4.0.3-py3-none-any.whl (43.4 MB)\\nRequirement already satisfied: numpy!=1.19.3 in /azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib/python3.6/site-packages (from azureml-dataset-runtime[fuse]~=1.42.0->azureml-defaults->-r /azureml-environment-setup/condaenv.pqz36maz.requirements.txt (line 1)) (1.19.2)\\nCollecting fusepy<4.0.0,>=3.0.1\\n  Downloading fusepy-3.0.1.tar.gz (11 kB)\\nCollecting pyyaml<7.0.0,>=5.1.0\\n  Downloading PyYAML-6.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (603 kB)\\nCollecting azure-identity==1.7.0\\n  Downloading azure_identity-1.7.0-py2.py3-none-any.whl (129 kB)\\nCollecting dotnetcore2<4.0.0,>=3.0.0\\n  Downloading dotnetcore2-3.1.23-py3-none-manylinux1_x86_64.whl (31.1 MB)\\nCollecting azureml-dataprep-rslex~=2.6.0dev0\\n  Downloading azureml_dataprep_rslex-2.6.3-cp36-cp36m-manylinux1_x86_64.whl (15.5 MB)\\nCollecting cloudpickle<3.0.0,>=1.1.0\\n  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\\nCollecting azureml-dataprep-native<39.0.0,>=38.0.0\\n  Downloading azureml_dataprep_native-38.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\\nCollecting jsonschema\\n  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\\nCollecting msal-extensions<=1.0.0,>=0.3.0\\n  Downloading msal_extensions-0.3.1-py2.py3-none-any.whl (18 kB)\\nCollecting inference-schema==1.3.0\\n  Downloading inference_schema-1.3.0-py3-none-any.whl (19 kB)\\nCollecting gunicorn==20.1.0\\n  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\\nCollecting click<8.0,>=5.1\\n  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\\nCollecting Jinja2<3.1,>=2.10.1\\n  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\\nCollecting Werkzeug<2.0,>=0.15\\n  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\\nCollecting itsdangerous<2.0,>=0.24\\n  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\\nCollecting applicationinsights>=0.11.7\\n  Downloading applicationinsights-0.11.10-py2.py3-none-any.whl (55 kB)\\nCollecting opencensus-ext-azure~=1.1.0\\n  Downloading opencensus_ext_azure-1.1.4-py2.py3-none-any.whl (40 kB)\\nCollecting flask==1.0.3\\n  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\\nRequirement already satisfied: setuptools>=3.0 in /azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib/python3.6/site-packages (from gunicorn==20.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->-r /azureml-environment-setup/condaenv.pqz36maz.requirements.txt (line 1)) (58.0.4)\\nCollecting wrapt<=1.12.1,>=1.11.1\\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\\nCollecting cffi>=1.12\\n  Downloading cffi-1.15.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (405 kB)\\nCollecting pycparser\\n  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\\nCollecting websocket-client>=0.32.0\\n  Downloading websocket_client-1.3.1-py3-none-any.whl (54 kB)\\nCollecting distro>=1.2.0\\n  Downloading distro-1.7.0-py3-none-any.whl (20 kB)\\nCollecting zipp>=0.5\\n  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\\nCollecting typing-extensions>=3.6.4\\n  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\\nCollecting MarkupSafe>=2.0\\n  Downloading MarkupSafe-2.0.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)\\nCollecting tabulate\\n  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\\nCollecting pygments\\n  Downloading Pygments-2.12.0-py3-none-any.whl (1.1 MB)\\nCollecting portalocker<3,>=1.0\\n  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\\nCollecting requests-oauthlib>=0.5.0\\n  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\\nRequirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib/python3.6/site-packages (from msrest<0.7.0,>=0.5.1->azureml-core~=1.42.0->azureml-defaults->-r /azureml-environment-setup/condaenv.pqz36maz.requirements.txt (line 1)) (2021.5.30)\\nCollecting isodate>=0.6.0\\n  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\\nCollecting pyasn1>=0.1.1\\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\\nCollecting opencensus<1.0.0,>=0.8.0\\n  Downloading opencensus-0.9.0-py2.py3-none-any.whl (128 kB)\\nCollecting psutil>=5.6.3\\n  Downloading psutil-5.9.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\\nCollecting opencensus-context>=0.1.2\\n  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\\nCollecting google-api-core<3.0.0,>=1.0.0\\n  Downloading google_api_core-2.8.1-py3-none-any.whl (114 kB)\\nCollecting protobuf<4.0.0dev,>=3.15.0\\n  Downloading protobuf-3.19.4-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\\nCollecting google-auth<3.0dev,>=1.25.0\\n  Downloading google_auth-2.7.0-py2.py3-none-any.whl (160 kB)\\nCollecting googleapis-common-protos<2.0dev,>=1.56.2\\n  Downloading googleapis_common_protos-1.56.2-py2.py3-none-any.whl (211 kB)\\nCollecting pyasn1-modules>=0.2.1\\n  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\\nCollecting cachetools<6.0,>=2.0.0\\n  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\\nCollecting rsa<5,>=3.1.4\\n  Downloading rsa-4.8-py3-none-any.whl (39 kB)\\nCollecting contextvars\\n  Downloading contextvars-2.4.tar.gz (9.6 kB)\\nCollecting pyparsing!=3.0.5,>=2.0.2\\n  Downloading pyparsing-3.0.7-py3-none-any.whl (98 kB)\\nCollecting pynacl>=1.0.1\\n  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\\nCollecting bcrypt>=3.1.3\\n  Downloading bcrypt-3.2.2-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (62 kB)\\nCollecting charset-normalizer~=2.0.0\\n  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\\nCollecting idna<4,>=2.5\\n  Downloading idna-3.3-py3-none-any.whl (61 kB)\\nCollecting oauthlib>=3.0.0\\n  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\\nCollecting PySocks!=1.5.7,>=1.5.6\\n  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\\nCollecting jeepney>=0.6\\n  Downloading jeepney-0.7.1-py3-none-any.whl (54 kB)\\nCollecting backports.weakref\\n  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\\nCollecting immutables>=0.9\\n  Downloading immutables-0.18-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (115 kB)\\nCollecting attrs>=17.4.0\\n  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)\\nCollecting pyrsistent>=0.14.0\\n  Downloading pyrsistent-0.18.0-cp36-cp36m-manylinux1_x86_64.whl (117 kB)\\nCollecting gitpython>=2.1.0\\n  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\\nCollecting entrypoints\\n  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\\nCollecting databricks-cli>=0.8.7\\n  Downloading databricks-cli-0.16.6.tar.gz (62 kB)\\nCollecting gitdb<5,>=4.0.1\\n  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\\nCollecting smmap<6,>=3.0.1\\n  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\\nBuilding wheels for collected packages: json-logging-py, fusepy, wrapt, contextvars, databricks-cli\\n  Building wheel for json-logging-py (setup.py): started\\n  Building wheel for json-logging-py (setup.py): finished with status \\'done\\'\\n  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=d80c29094229ec4e1e4a3e5cf07dd6d108efd606e17cfd6da7f74c443780a702\\n  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\\n  Building wheel for fusepy (setup.py): started\\n  Building wheel for fusepy (setup.py): finished with status \\'done\\'\\n  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=41f7b9b9b446e73bcef0e5adba5918e35c5e165d61a5663ab3856a275bc008a6\\n  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\\n  Building wheel for wrapt (setup.py): started\\n  Building wheel for wrapt (setup.py): finished with status \\'done\\'\\n  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=69940 sha256=8c99581ddaa44f51dfb8625fa0a4a1dc15c16f9ba6a4910592d6bc7f346f8ed5\\n  Stored in directory: /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\\n  Building wheel for contextvars (setup.py): started\\n  Building wheel for contextvars (setup.py): finished with status \\'done\\'\\n  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7681 sha256=9511b9aab118c67aaedf1e8710f50770791bbe01d8829f1be07a9f0a40baaa5e\\n  Stored in directory: /root/.cache/pip/wheels/41/11/53/911724983aa48deb94792432e14e518447212dd6c5477d49d3\\n  Building wheel for databricks-cli (setup.py): started\\n  Building wheel for databricks-cli (setup.py): finished with status \\'done\\'\\n  Created wheel for databricks-cli: filename=databricks_cli-0.16.6-py3-none-any.whl size=112631 sha256=b8c3f267412a28e7e4e51c6f11b1240a310371fdb550b467bb7627f1ab301751\\n  Stored in directory: /root/.cache/pip/wheels/68/76/52/8642fd2d5677e988a77b543279f7732ec5d1549bf4ee05c3c6\\nSuccessfully built json-logging-py fusepy wrapt contextvars databricks-cli\\nInstalling collected packages: pycparser, cffi, urllib3, PyJWT, idna, cryptography, charset-normalizer, typing-extensions, requests, pyasn1, zipp, rsa, pyasn1-modules, protobuf, portalocker, oauthlib, msal, immutables, cachetools, requests-oauthlib, pyrsistent, msal-extensions, isodate, importlib-metadata, googleapis-common-protos, google-auth, distro, contextvars, azure-core, attrs, smmap, pyyaml, opencensus-context, msrest, MarkupSafe, jsonschema, google-api-core, dotnetcore2, cloudpickle, azureml-dataprep-rslex, azureml-dataprep-native, azure-identity, adal, wrapt, Werkzeug, websocket-client, tabulate, PySocks, pyparsing, pyopenssl, pynacl, pygments, pyarrow, psutil, opencensus, msrestazure, jmespath, Jinja2, jeepney, itsdangerous, gitdb, click, bcrypt, backports.weakref, azureml-dataprep, azure-mgmt-core, azure-common, argcomplete, SecretStorage, pkginfo, pathspec, paramiko, packaging, opencensus-ext-azure, ndg-httpsclient, knack, jsonpickle, inference-schema, humanfriendly, gunicorn, gitpython, fusepy, flask, entrypoints, docker, databricks-cli, contextlib2, backports.tempfile, azureml-dataset-runtime, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, azure-graphrbac, applicationinsights, mlflow-skinny, json-logging-py, configparser, azureml-inference-server-http, azureml-core, azureml-mlflow, azureml-defaults\\nSuccessfully installed Jinja2-3.0.3 MarkupSafe-2.0.1 PyJWT-2.4.0 PySocks-1.7.1 SecretStorage-3.3.2 Werkzeug-1.0.1 adal-1.2.7 applicationinsights-0.11.10 argcomplete-2.0.0 attrs-21.4.0 azure-common-1.1.28 azure-core-1.22.1 azure-graphrbac-0.61.1 azure-identity-1.7.0 azure-mgmt-authorization-2.0.0 azure-mgmt-containerregistry-9.1.0 azure-mgmt-core-1.3.0 azure-mgmt-keyvault-9.3.0 azure-mgmt-resource-21.0.0 azure-mgmt-storage-20.0.0 azureml-core-1.42.0.post1 azureml-dataprep-4.0.3 azureml-dataprep-native-38.0.0 azureml-dataprep-rslex-2.6.3 azureml-dataset-runtime-1.42.0 azureml-defaults-1.42.0 azureml-inference-server-http-0.4.13 azureml-mlflow-1.42.0 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-3.2.2 cachetools-4.2.4 cffi-1.15.0 charset-normalizer-2.0.12 click-7.1.2 cloudpickle-2.1.0 configparser-3.7.4 contextlib2-21.6.0 contextvars-2.4 cryptography-36.0.2 databricks-cli-0.16.6 distro-1.7.0 docker-5.0.3 dotnetcore2-3.1.23 entrypoints-0.4 flask-1.0.3 fusepy-3.0.1 gitdb-4.0.9 gitpython-3.1.18 google-api-core-2.8.1 google-auth-2.7.0 googleapis-common-protos-1.56.2 gunicorn-20.1.0 humanfriendly-10.0 idna-3.3 immutables-0.18 importlib-metadata-4.8.3 inference-schema-1.3.0 isodate-0.6.1 itsdangerous-1.1.0 jeepney-0.7.1 jmespath-0.10.0 json-logging-py-0.2 jsonpickle-2.2.0 jsonschema-3.2.0 knack-0.9.0 mlflow-skinny-1.23.1 msal-1.18.0 msal-extensions-0.3.1 msrest-0.6.21 msrestazure-0.6.4 ndg-httpsclient-0.5.1 oauthlib-3.2.0 opencensus-0.9.0 opencensus-context-0.1.2 opencensus-ext-azure-1.1.4 packaging-21.3 paramiko-2.11.0 pathspec-0.9.0 pkginfo-1.8.3 portalocker-2.4.0 protobuf-3.19.4 psutil-5.9.1 pyarrow-3.0.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.21 pygments-2.12.0 pynacl-1.5.0 pyopenssl-22.0.0 pyparsing-3.0.7 pyrsistent-0.18.0 pyyaml-6.0 requests-2.27.1 requests-oauthlib-1.3.1 rsa-4.8 smmap-5.0.0 tabulate-0.8.9 typing-extensions-4.1.1 urllib3-1.26.9 websocket-client-1.3.1 wrapt-1.12.1 zipp-3.6.0\\n\\ndone\\n#\\n# To activate this environment, use\\n#\\n#     $ conda activate /azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61\\n#\\n# To deactivate an active environment, use\\n#\\n#     $ conda deactivate\\n\\n\\x1b[91m\\n\\n==> WARNING: A newer version of conda exists. <==\\n  current version: 4.9.2\\n  latest version: 4.13.0\\n\\nPlease update conda by running\\n\\n    $ conda update -n base -c defaults conda\\n\\n\\n\\x1b[0mWARNING: /root/.conda/pkgs does not exist\\nRemoving intermediate container 1a71244fe4b9\\n ---> 3571e4f55a4c\\nStep 9/17 : ENV PATH /azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/bin:$PATH\\n ---> Running in 2cfd7fae64a6\\nRemoving intermediate container 2cfd7fae64a6\\n ---> 1be96172562e\\nStep 10/17 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61\\n ---> Running in 3a3cb1dded7c\\nRemoving intermediate container 3a3cb1dded7c\\n ---> a9d25dcc2c1e\\nStep 11/17 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib:$LD_LIBRARY_PATH\\n ---> Running in 6f3e84981116\\nRemoving intermediate container 6f3e84981116\\n ---> 96097a0a5af6\\nStep 12/17 : ENV CONDA_DEFAULT_ENV=azureml_809a074975457de1dd27bdfcf2d79d61 CONDA_PREFIX=/azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61\\n ---> Running in 518455bf6455\\nRemoving intermediate container 518455bf6455\\n ---> 08cddc886b9f\\nStep 13/17 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\\n ---> 40e70159046e\\nStep 14/17 : RUN if [ $SPARK_HOME ]; then /bin/bash -c \\'$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py\\'; fi\\n ---> Running in 49883a5d897f\\nRemoving intermediate container 49883a5d897f\\n ---> feefbbf49db1\\nStep 15/17 : RUN rm -rf azureml-environment-setup\\n ---> Running in 816700f21c0a\\nRemoving intermediate container 816700f21c0a\\n ---> 3e170fa4ecfa\\nStep 16/17 : ENV AZUREML_ENVIRONMENT_IMAGE True\\n ---> Running in 208d94e37187\\nRemoving intermediate container 208d94e37187\\n ---> 50a0e2be6580\\nStep 17/17 : CMD [\"bash\"]\\n ---> Running in de051409ad77\\nRemoving intermediate container de051409ad77\\n ---> 66c83b5659d9\\nSuccessfully built 66c83b5659d9\\nSuccessfully tagged azureml/azureml_69e2aae1dd257f36fb2e15140cb037e9:latest\\n\\n\\n\\n\\n[2022-06-09T22:54:07.042333] Logging experiment running status in history service.\\nRunning: [\\'docker\\', \\'run\\', \\'--name\\', \\'mslearn-diabetes_1654815067_d3e584ca\\', \\'--rm\\', \\'-v\\', \\'/tmp/azureml_runs/mslearn-diabetes_1654815067_d3e584ca:/azureml-run\\', \\'--shm-size\\', \\'2g\\', \\'-e\\', \\'AZUREML_LOCALRUN=true\\', \\'-e\\', \\'AZUREML_CURRENT_CLOUD_METADATA={\"Portal\":\"https://portal.azure.com\",\"Authentication\":{\"AzureDataLakeStoreFileSystem\":null,\"SqlServerHostname\":null,\"AzureDataLakeAnalyticsCatalogAndJob\":null,\"KeyVaultDns\":null,\"Storage\":null,\"AzureFrontDoorEndpointSuffix\":null},\"Media\":\"https://rest.media.azure.net\",\"GraphAudience\":\"https://graph.windows.net/\",\"Graph\":\"https://graph.windows.net/\",\"Name\":\"AzureCloud\",\"Suffixes\":{\"LoginEndpoint\":null,\"Audiences\":null,\"Tenant\":null,\"IdentityProvider\":null},\"Batch\":\"https://batch.core.windows.net/\",\"ResourceManager\":\"https://management.azure.com/\",\"VmImageAliasDoc\":\"https://raw.githubusercontent.com/Azure/azure-rest-api-specs/master/arm-compute/quickstart-templates/aliases.json\",\"ActiveDirectoryDataLake\":\"https://datalake.azure.net/\",\"SqlManagement\":\"https://management.core.windows.net:8443/\",\"Gallery\":\"https://gallery.azure.com/\"}\\', \\'-e\\', \\'AZUREML_CURRENT_CLOUD=AzureCloud\\', \\'-e\\', \\'MLFLOW_TRACKING_TOKEN=eyJhbGciOiJSUzI1NiIsImtpZCI6Ijc3NzQ2QzI0NjRBODE1QzlCNUQwMUFBRDVCNThEREJBQTUwQ0VDRkQiLCJ0eXAiOiJKV1QifQ.eyJyb2xlIjoiQ29udHJpYnV0b3IiLCJzY29wZSI6Ii9zdWJzY3JpcHRpb25zLzczNzExYmY1LTRjZGEtNGFjYS04OTNkLTdlMTZjZWE0NmUzNi9yZXNvdXJjZUdyb3Vwcy9kcDEwMC9wcm92aWRlcnMvTWljcm9zb2Z0Lk1hY2hpbmVMZWFybmluZ1NlcnZpY2VzL3dvcmtzcGFjZXMvZHAxMDBfbWx3cyIsImFjY291bnRpZCI6IjAwMDAwMDAwLTAwMDAtMDAwMC0wMDAwLTAwMDAwMDAwMDAwMCIsIndvcmtzcGFjZUlkIjoiYThmMjcyZDMtMGZiNi00YTA4LTg5NjQtMDk4YTM1ZDUxODRkIiwicHJvamVjdGlkIjoiMDAwMDAwMDAtMDAwMC0wMDAwLTAwMDAtMDAwMDAwMDAwMDAwIiwiZGlzY292ZXJ5IjoidXJpOi8vZGlzY292ZXJ5dXJpLyIsInRpZCI6ImU3MTRlZjMxLWZhYWItNDFkMi05ZjFlLWU2ZGY0YWYxNmFiOCIsIm9pZCI6ImI0NjY2NmRmLWM4ZWMtNGEzNi05MjdmLTc0YjNiMmNmMzczYiIsInB1aWQiOiIxMDAzMjAwMUY3RTgxMjEwIiwiaXNzIjoiYXp1cmVtbCIsImFwcGlkIjoiQXJwYW4gVmVudWdvcGFsIiwiZXhwIjoxNjU2NjI5NDY4LCJhdWQiOiJhenVyZW1sIn0.kxyQS6QL-yVbV7LETEjDoW34uzXOzp712hrXQNRf8MBZdN006AGR7srYF6Kj6h9QKNBYZXKcnhTCJgD4yK-I4XadgwkHNzi6sAcHw45liU0349j6IBYVR79CiNNDo7qzMXQOOJAKaLjZuNDxgfOxh_CJlwxXicseLfrbhqKzQoSblqgKHfWG3AW3oiYV0Buhb6SpBx-xodybfKWAx1eGeCjSfOX5zRdV5G3OsHjlitj9uVsoK9DC8juhxgxSO33dGBsJoz86E3evIYz8HDQsrvqLcboGt1N5XuDcv1sbUecNF-pYcSTka2d7Vv5VO_Lihr6VEedxp1lLoZgDo5DRVQ\\', \\'-e\\', \\'MLFLOW_TRACKING_URI=azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/73711bf5-4cda-4aca-893d-7e16cea46e36/resourceGroups/dp100/providers/Microsoft.MachineLearningServices/workspaces/dp100_mlws\\', \\'-e\\', \\'MLFLOW_RUN_ID=mslearn-diabetes_1654815067_d3e584ca\\', \\'-e\\', \\'MLFLOW_EXPERIMENT_NAME=mslearn-diabetes\\', \\'-e\\', \\'MLFLOW_EXPERIMENT_ID=037785c8-09cd-4ca7-bd5e-b26365dfd8a8\\', \\'-e\\', \\'EXAMPLE_ENV_VAR=EXAMPLE_VALUE\\', \\'-e\\', \\'AZUREML_CONTEXT_MANAGER_TRACKUSERERROR=eyJTa2lwSGlzdG9yeUltcG9ydENoZWNrIjoiRmFsc2UifQ==\\', \\'-e\\', \\'AZUREML_CONTEXT_MANAGER_RUNHISTORY=eyJPdXRwdXRDb2xsZWN0aW9uIjp0cnVlLCJEaXJlY3Rvcmllc1RvV2F0Y2giOlsibG9ncyJdLCJFbmFibGVNTGZsb3dUcmFja2luZyI6dHJ1ZSwic25hcHNob3RQcm9qZWN0Ijp0cnVlfQ==\\', \\'-e\\', \\'AZUREML_CONTEXT_MANAGER_PROJECTPYTHONPATH=bnVsbA==\\', \\'-e\\', \\'AZUREML_RUN_TOKEN_EXPIRY=1656629468\\', \\'-e\\', \\'AZUREML_RUN_TOKEN=eyJhbGciOiJSUzI1NiIsImtpZCI6Ijc3NzQ2QzI0NjRBODE1QzlCNUQwMUFBRDVCNThEREJBQTUwQ0VDRkQiLCJ0eXAiOiJKV1QifQ.eyJyb2xlIjoiQ29udHJpYnV0b3IiLCJzY29wZSI6Ii9zdWJzY3JpcHRpb25zLzczNzExYmY1LTRjZGEtNGFjYS04OTNkLTdlMTZjZWE0NmUzNi9yZXNvdXJjZUdyb3Vwcy9kcDEwMC9wcm92aWRlcnMvTWljcm9zb2Z0Lk1hY2hpbmVMZWFybmluZ1NlcnZpY2VzL3dvcmtzcGFjZXMvZHAxMDBfbWx3cyIsImFjY291bnRpZCI6IjAwMDAwMDAwLTAwMDAtMDAwMC0wMDAwLTAwMDAwMDAwMDAwMCIsIndvcmtzcGFjZUlkIjoiYThmMjcyZDMtMGZiNi00YTA4LTg5NjQtMDk4YTM1ZDUxODRkIiwicHJvamVjdGlkIjoiMDAwMDAwMDAtMDAwMC0wMDAwLTAwMDAtMDAwMDAwMDAwMDAwIiwiZGlzY292ZXJ5IjoidXJpOi8vZGlzY292ZXJ5dXJpLyIsInRpZCI6ImU3MTRlZjMxLWZhYWItNDFkMi05ZjFlLWU2ZGY0YWYxNmFiOCIsIm9pZCI6ImI0NjY2NmRmLWM4ZWMtNGEzNi05MjdmLTc0YjNiMmNmMzczYiIsInB1aWQiOiIxMDAzMjAwMUY3RTgxMjEwIiwiaXNzIjoiYXp1cmVtbCIsImFwcGlkIjoiQXJwYW4gVmVudWdvcGFsIiwiZXhwIjoxNjU2NjI5NDY4LCJhdWQiOiJhenVyZW1sIn0.kxyQS6QL-yVbV7LETEjDoW34uzXOzp712hrXQNRf8MBZdN006AGR7srYF6Kj6h9QKNBYZXKcnhTCJgD4yK-I4XadgwkHNzi6sAcHw45liU0349j6IBYVR79CiNNDo7qzMXQOOJAKaLjZuNDxgfOxh_CJlwxXicseLfrbhqKzQoSblqgKHfWG3AW3oiYV0Buhb6SpBx-xodybfKWAx1eGeCjSfOX5zRdV5G3OsHjlitj9uVsoK9DC8juhxgxSO33dGBsJoz86E3evIYz8HDQsrvqLcboGt1N5XuDcv1sbUecNF-pYcSTka2d7Vv5VO_Lihr6VEedxp1lLoZgDo5DRVQ\\', \\'-e\\', \\'AZUREML_ROOT_RUN_ID=mslearn-diabetes_1654815067_d3e584ca\\', \\'-e\\', \\'AZUREML_COMPUTE_RECORD_ARTIFACT_ORIGIN=ComputeRecord\\', \\'-e\\', \\'AZUREML_COMPUTE_RECORD_ARTIFACT_PATH=compute_record.txt\\', \\'-e\\', \\'HBI_WORKSPACE_JOB=false\\', \\'-e\\', \\'AZUREML_RUN_TOKEN_RAND=a18c79d8-d3e3-48ab-b79a-e217a47f15d7\\', \\'-e\\', \\'AZUREML_RUN_TOKEN_PASS=ce947657-b74c-41d3-a647-bbe70d6eed9b\\', \\'-e\\', \\'PYTHONUNBUFFERED=True\\', \\'-e\\', \\'AZUREML_COMMUNICATOR=None\\', \\'-e\\', \\'AZUREML_FRAMEWORK=Python\\', \\'-e\\', \\'AZUREML_EXPERIMENT_ID=037785c8-09cd-4ca7-bd5e-b26365dfd8a8\\', \\'-e\\', \\'AZUREML_ARM_PROJECT_NAME=mslearn-diabetes\\', \\'-e\\', \\'AZUREML_ARM_WORKSPACE_NAME=dp100_mlws\\', \\'-e\\', \\'AZUREML_ARM_SUBSCRIPTION=73711bf5-4cda-4aca-893d-7e16cea46e36\\', \\'-e\\', \\'AZUREML_ARM_RESOURCEGROUP=dp100\\', \\'-e\\', \\'AZUREML_EXPERIMENT_SCOPE=/subscriptions/73711bf5-4cda-4aca-893d-7e16cea46e36/resourceGroups/dp100/providers/Microsoft.MachineLearningServices/workspaces/dp100_mlws/experiments/mslearn-diabetes\\', \\'-e\\', \\'AZUREML_WORKSPACE_ID=a8f272d3-0fb6-4a08-8964-098a35d5184d\\', \\'-e\\', \\'AZUREML_WORKSPACE_SCOPE=/subscriptions/73711bf5-4cda-4aca-893d-7e16cea46e36/resourceGroups/dp100/providers/Microsoft.MachineLearningServices/workspaces/dp100_mlws\\', \\'-e\\', \\'AZUREML_DATA_CONTAINER_ID=dcid.mslearn-diabetes_1654815067_d3e584ca\\', \\'-e\\', \\'AZUREML_DISCOVERY_SERVICE_ENDPOINT=https://eastus.api.azureml.ms/discovery\\', \\'-e\\', \\'AZUREML_RUN_HISTORY_SERVICE_ENDPOINT=https://eastus.api.azureml.ms\\', \\'-e\\', \\'AZUREML_SERVICE_ENDPOINT=https://eastus.api.azureml.ms\\', \\'-e\\', \\'AZUREML_RUN_CONFIGURATION=azureml-setup/mutated_run_configuration.json\\', \\'-e\\', \\'AZUREML_INSTRUMENTATION_KEY=2d586587-4df8-4336-9af2-277fe3c5d9cd\\', \\'-e\\', \\'AZUREML_DRIVERLOG_PATH=azureml-logs/driver_log.txt\\', \\'-e\\', \\'TELEMETRY_LOGS=azureml-logs/telemetry_logs/\\', \\'-e\\', \\'FAIRLEARN_LOGS=azureml-logs/telemetry_logs/fairlearn_log.txt\\', \\'-e\\', \\'INTERPRET_TEXT_LOGS=azureml-logs/telemetry_logs/interpret_text_log.txt\\', \\'-e\\', \\'INTERPRET_C_LOGS=azureml-logs/telemetry_logs/interpret_community_log.txt\\', \\'-e\\', \\'AZUREML_JOBRELEASELOG_PATH=azureml-logs/job_release_log.txt\\', \\'-e\\', \\'AZUREML_JOBPREPLOG_PATH=azureml-logs/job_prep_log.txt\\', \\'-e\\', \\'AZUREML_CONTROLLOG_PATH=azureml-logs/control_log.txt\\', \\'-e\\', \\'AZUREML_LOGDIRECTORY_PATH=azureml-logs/\\', \\'-e\\', \\'AZUREML_PIDFILE_PATH=azureml-setup/pid.txt\\', \\'-e\\', \\'AZUREML_RUN_ID=mslearn-diabetes_1654815067_d3e584ca\\', \\'azureml/azureml_69e2aae1dd257f36fb2e15140cb037e9\\', \\'/bin/bash\\', \\'-c\\', \\'cd /azureml-run && \"/azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/bin/python\" \"azureml-setup/run_script.py\" \"/azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/bin/python\" \"azureml-setup/context_manager_injector.py\" \"-i\" \"ProjectPythonPath:context_managers.ProjectPythonPath\" \"-i\" \"RunHistory:context_managers.RunHistory\" \"-i\" \"TrackUserError:context_managers.TrackUserError\" \"diabetes_experiment.py\"\\']\\nStreaming log file azureml-logs/70_driver_log.txt\\nStarting the daemon thread to refresh tokens in background for process with pid = 1\\nScript process exited with code 0\\nUploading driver log...\\nFinalizing run...\\n[2022-06-09T22:54:17.758905] get vm size and vm region successfully.\\n[2022-06-09T22:54:17.780247] get compute meta data successfully.\\n[2022-06-09T22:54:17.917558] post artifact meta request successfully.\\n[2022-06-09T22:54:17.956255] upload compute record artifact successfully.\\n\\nScript process exited with code 0\\n\\n\\n\\nUploading control log...\\n',\n",
              "  'azureml-logs/70_driver_log.txt': \"[2022-06-09T22:54:07.886922] Entering context manager injector.\\nCannot provide tracer without any exporter configured.\\n[2022-06-09T22:54:08.507023] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['diabetes_experiment.py'])\\nScript type = None\\n[2022-06-09T22:54:08.510221] Entering Run History Context Manager.\\n/azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib/python3.6/site-packages/azureml/history/_tracking.py:186: FutureWarning: MLflow support for Python 3.6 is deprecated and will be dropped in an upcoming release. At that point, existing Python 3.6 workflows that use MLflow will continue to work without modification, but Python 3.6 users will no longer get access to the latest MLflow features and bugfixes. We recommend that you upgrade to Python 3.7 or newer.\\n  import mlflow\\n[2022-06-09T22:54:10.744540] Current directory: /azureml-run\\n[2022-06-09T22:54:10.744568] Preparing to call script [diabetes_experiment.py] with arguments:[]\\n[2022-06-09T22:54:10.744586] After variable expansion, calling script [diabetes_experiment.py] with arguments:[]\\n\\nAnalyzing 10000 rows of data\\n0    6656\\n1    3344\\nName: Diabetic, dtype: int64\\n\\n\\n[2022-06-09T22:54:16.288694] The experiment completed successfully. Finalizing run...\\n[2022-06-09T22:54:16.288721] Start FinalizingInRunHistory\\n[2022-06-09T22:54:16.290856] Logging experiment finalizing status in history service.\\nStarting the daemon thread to refresh tokens in background for process with pid = 8\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\n2 items cleaning up...\\nCleanup took 0.10537052154541016 seconds\\n[2022-06-09T22:54:17.298168] Finished context manager injector.\\n\",\n",
              "  'logs/azureml/8_azureml.log': \"2022-06-09 22:54:08,510|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True}, track_folders: None, deny_list: None, directories_to_watch: ['logs', 'logs/azureml']\\n2022-06-09 22:54:08,511|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: none\\n2022-06-09 22:54:08,511|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2022-06-09 22:54:08,511|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2022-06-09 22:54:09,058|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7f931db3d598> for run source azureml.scriptrun\\n2022-06-09 22:54:09,059|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2022-06-09 22:54:09,060|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2022-06-09 22:54:09,064|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2022-06-09 22:54:09,075|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2022-06-09 22:54:09,075|azureml.core.authentication|DEBUG|Time to expire 1814218.92413 seconds\\n2022-06-09 22:54:09,076|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2022-06-09 22:54:09,076|azureml._restclient.clientbase|DEBUG|ClientBase: Calling get with url None\\n2022-06-09 22:54:09,109|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-06-09 22:54:09,110|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-06-09 22:54:09,110|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-06-09 22:54:09,110|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-06-09 22:54:09,110|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-06-09 22:54:09,111|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-06-09 22:54:09,111|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-06-09 22:54:09,254|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2022-06-09 22:54:09,254|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2022-06-09 22:54:09,311|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2022-06-09 22:54:09,312|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': '7d853180-84b7-46da-9b2b-e656a4d5ca81', 'azureml.git.repository_uri': 'https://github.com/arpan-ta/mslearn-dp100.git', 'mlflow.source.git.repoURL': 'https://github.com/arpan-ta/mslearn-dp100.git', 'azureml.git.branch': 'main', 'mlflow.source.git.branch': 'main', 'azureml.git.commit': 'd2354e40eec31c22eb09381c6a890311cccc30c9', 'mlflow.source.git.commit': 'd2354e40eec31c22eb09381c6a890311cccc30c9', 'azureml.git.dirty': 'True'}\\n2022-06-09 22:54:09,312|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2022-06-09 22:54:09,985|azureml|DEBUG|Installed with mlflow version 1.23.1.\\n2022-06-09 22:54:09,986|azureml.mlflow|DEBUG|Setting up a Remote MLflow run\\n2022-06-09 22:54:09,987|azureml.mlflow|DEBUG|Creating a tracking uri in eastus.api.azureml.ms for workspace /subscriptions/73711bf5-4cda-4aca-893d-7e16cea46e36/resourceGroups/dp100/providers/Microsoft.MachineLearningServices/workspaces/dp100_mlws\\n2022-06-09 22:54:09,988|azureml.mlflow|DEBUG|Setting MLflow tracking uri env var\\n2022-06-09 22:54:09,988|azureml.mlflow|DEBUG|Setting MLflow run id env var with mslearn-diabetes_1654815067_d3e584ca\\n2022-06-09 22:54:09,988|azureml.mlflow|DEBUG|Setting Mlflow experiment with mslearn-diabetes\\n2022-06-09 22:54:09,988|azureml.mlflow|DEBUG|Setting Mlflow experiment with 037785c8-09cd-4ca7-bd5e-b26365dfd8a8\\n2022-06-09 22:54:09,989|azureml.mlflow|DEBUG|Setting the mlflow tag mlflow.source.type\\n2022-06-09 22:54:09,989|azureml.mlflow|DEBUG|Setting the mlflow tag mlflow.source.name\\n2022-06-09 22:54:09,989|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.RunClient.get_details-async:False|DEBUG|[START]\\n2022-06-09 22:54:09,990|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_details with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/details\\n2022-06-09 22:54:10,099|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.RunClient.get_details-async:False|DEBUG|[STOP]\\n2022-06-09 22:54:10,102|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient|DEBUG|Fetching files for prefix in ExperimentRun, dcid.mslearn-diabetes_1654815067_d3e584ca, user_logs\\n2022-06-09 22:54:10,102|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix-async:True|DEBUG|[START]\\n2022-06-09 22:54:10,103|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _execute_with_base_arguments\\n2022-06-09 22:54:10,103|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling list_sas_by_prefix with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/prefix/contentinfo/{origin}/{container}/{path}\\n2022-06-09 22:54:10,107|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix|DEBUG|Using basic handler - no exception handling\\n2022-06-09 22:54:10,107|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix-async:True|DEBUG|[STOP]\\n2022-06-09 22:54:10,108|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|[START]\\n2022-06-09 22:54:10,108|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|Awaiter is ApiPagination\\n2022-06-09 22:54:10,169|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|[STOP]\\n2022-06-09 22:54:10,170|azureml._restclient.clientbase|DEBUG|Found continuation_token field in DTO\\n2022-06-09 22:54:10,171|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient|DEBUG|Fetching files for prefix in ExperimentRun, dcid.mslearn-diabetes_1654815067_d3e584ca, system_logs\\n2022-06-09 22:54:10,171|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix-async:True|DEBUG|[START]\\n2022-06-09 22:54:10,171|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _execute_with_base_arguments\\n2022-06-09 22:54:10,171|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling list_sas_by_prefix with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/prefix/contentinfo/{origin}/{container}/{path}\\n2022-06-09 22:54:10,171|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix|DEBUG|Using basic handler - no exception handling\\n2022-06-09 22:54:10,172|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix-async:True|DEBUG|[STOP]\\n2022-06-09 22:54:10,172|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|[START]\\n2022-06-09 22:54:10,172|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|Awaiter is ApiPagination\\n2022-06-09 22:54:10,666|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|[STOP]\\n2022-06-09 22:54:10,666|azureml._restclient.clientbase|DEBUG|Found continuation_token field in DTO\\n2022-06-09 22:54:10,667|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[START]\\n2022-06-09 22:54:10,667|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling patch_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2022-06-09 22:54:10,742|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[STOP]\\n2022-06-09 22:54:10,742|azureml.WorkerPool|DEBUG|[START]\\n2022-06-09 22:54:10,742|azureml.SendRunKillSignal|DEBUG|[START]\\n2022-06-09 22:54:10,742|azureml.RunStatusContext|DEBUG|[START]\\n2022-06-09 22:54:10,742|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunContextManager.RunStatusContext|DEBUG|[START]\\n2022-06-09 22:54:10,742|azureml.MetricsClient|DEBUG|[START]\\n2022-06-09 22:54:10,742|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2022-06-09 22:54:10,742|azureml.ContentUploader|DEBUG|[START]\\n2022-06-09 22:54:10,743|azureml._history.utils.context_managers|DEBUG|starting file watcher\\n2022-06-09 22:54:10,744|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Start]\\n2022-06-09 22:54:10,744|azureml.TrackFolders|DEBUG|[START]\\n2022-06-09 22:54:10,744|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2022-06-09 22:54:10,744|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2022-06-09 22:54:10,744|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /azureml-run\\n2022-06-09 22:54:10,744|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2022-06-09 22:54:10,744|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /azureml-run\\n2022-06-09 22:54:10,755|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2022-06-09 22:54:10,755|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2022-06-09 22:54:10,755|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2022-06-09 22:54:10,756|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-06-09 22:54:10,756|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-06-09 22:54:10,756|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-06-09 22:54:10,756|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-06-09 22:54:10,757|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-06-09 22:54:10,757|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-06-09 22:54:10,757|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-06-09 22:54:10,793|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2022-06-09 22:54:10,793|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2022-06-09 22:54:10,796|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2022-06-09 22:54:10,796|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2022-06-09 22:54:10,848|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2022-06-09 22:54:10,850|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': '7d853180-84b7-46da-9b2b-e656a4d5ca81', 'azureml.git.repository_uri': 'https://github.com/arpan-ta/mslearn-dp100.git', 'mlflow.source.git.repoURL': 'https://github.com/arpan-ta/mslearn-dp100.git', 'azureml.git.branch': 'main', 'mlflow.source.git.branch': 'main', 'azureml.git.commit': 'd2354e40eec31c22eb09381c6a890311cccc30c9', 'mlflow.source.git.commit': 'd2354e40eec31c22eb09381c6a890311cccc30c9', 'azureml.git.dirty': 'True'}\\n2022-06-09 22:54:10,850|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2022-06-09 22:54:10,867|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2022-06-09 22:54:10,867|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2022-06-09 22:54:10,867|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2022-06-09 22:54:10,874|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca|INFO|complete is not setting status for submitted runs.\\n2022-06-09 22:54:10,874|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2022-06-09 22:54:10,874|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2022-06-09 22:54:10,874|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2022-06-09 22:54:10,874|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2022-06-09 22:54:10,874|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2022-06-09 22:54:10,874|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2022-06-09 22:54:10,874|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2022-06-09 22:54:10,875|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2022-06-09 22:54:10,875|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2022-06-09 22:54:10,875|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2022-06-09 22:54:10,875|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2022-06-09 22:54:10,876|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 3.\\n2022-06-09 22:54:10,876|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2022-06-09 22:54:10,876|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2022-06-09 22:54:10,876|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2022-06-09 22:54:10,876|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 3 values.\\n2022-06-09 22:54:10,877|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2022-06-09 22:54:10,877|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2022-06-09 22:54:10,877|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2022-06-09 22:54:10,877|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\n2022-06-09 22:54:10,877|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2022-06-09 22:54:10,877|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2022-06-09 22:54:10,877|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2022-06-09 22:54:10,881|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2022-06-09 22:54:10,882|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2022-06-09 22:54:10,882|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2022-06-09 22:54:10,882|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2022-06-09 22:54:10,882|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2022-06-09 22:54:10,882|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2022-06-09 22:54:10,882|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2022-06-09 22:54:10,882|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2022-06-09 22:54:10,882|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0__log_batch_v2)].\\n2022-06-09 22:54:10,982|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2022-06-09 22:54:11,021|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.mslearn-diabetes_1654815067_d3e584ca/logs/azureml/8_azureml.log path: /azureml-run/logs/azureml/8_azureml.log\\n2022-06-09 22:54:11,022|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-06-09 22:54:11,022|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result|DEBUG|Using basic handler - no exception handling\\n2022-06-09 22:54:11,022|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 0_result to queue of approximate size: 0\\n2022-06-09 22:54:11,114|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2022-06-09 22:54:11,132|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[START]\\n2022-06-09 22:54:11,133|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2022-06-09 22:54:11,133|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2022-06-09 22:54:11,133|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Waiting on task: 0__log_batch_v2.\\n1 tasks left. Current duration of flush 0.00010275840759277344 seconds.\\n\\n2022-06-09 22:54:11,133|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2022-06-09 22:54:11,133|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2022-06-09 22:54:11,133|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2022-06-09 22:54:11,133|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2022-06-09 22:54:11,191|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2022-06-09 22:54:16,197|azureml._restclient.clientbase|DEBUG|ClientBase: Calling update_status with url None\\n2022-06-09 22:54:16,288|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: [], excluding []\\n2022-06-09 22:54:16,288|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\n2022-06-09 22:54:16,382|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2022-06-09 22:54:16,383|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /azureml-run\\n2022-06-09 22:54:16,383|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /azureml-run to /azureml-run\\n2022-06-09 22:54:16,383|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /azureml-run\\n2022-06-09 22:54:16,383|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2022-06-09 22:54:16,383|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2022-06-09 22:54:16,383|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: ['./outputs'], excluding ['azureml-logs/driver_log']\\n2022-06-09 22:54:16,383|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\n2022-06-09 22:54:16,383|azureml.history._tracking.PythonWorkingDirectory|DEBUG|./outputs exists as directory, uploading..\\n2022-06-09 22:54:16,383|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Found and adding path to upload: ./outputs/sample.csv\\n2022-06-09 22:54:16,383|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Paths to upload is ['./outputs/sample.csv'] in dir ./outputs\\n2022-06-09 22:54:16,384|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Overriding default timeout to 300\\n2022-06-09 22:54:16,384|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|[Start]\\n2022-06-09 22:54:16,384|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2022-06-09 22:54:16,384|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2022-06-09 22:54:16,539|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2022-06-09 22:54:16,539|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: perform_upload\\n2022-06-09 22:54:16,540|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload|DEBUG|Using basic handler - no exception handling\\n2022-06-09 22:54:16,540|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\n2022-06-09 22:54:16,540|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Adding task 0_perform_upload to queue of approximate size: 0\\n2022-06-09 22:54:16,541|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|[Stop] - waiting default timeout\\n2022-06-09 22:54:16,542|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|[START]\\n2022-06-09 22:54:16,542|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|Overriding default flush timeout from None to 300\\n2022-06-09 22:54:16,542|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0_perform_upload)].\\n2022-06-09 22:54:16,605|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.mslearn-diabetes_1654815067_d3e584ca/outputs/sample.csv with size 5529, file size 5529.\\n2022-06-09 22:54:16,792|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|[START]\\n2022-06-09 22:54:16,793|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|Awaiter is upload_files\\n2022-06-09 22:54:16,793|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|[STOP]\\n2022-06-09 22:54:16,793|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Waiting on task: 0_perform_upload.\\n1 tasks left. Current duration of flush 0.00010371208190917969 seconds.\\n\\n2022-06-09 22:54:16,793|azureml._SubmittedRun#mslearn-diabetes_1654815067_d3e584ca.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|[STOP]\\n2022-06-09 22:54:16,793|azureml.TrackFolders|DEBUG|[STOP]\\n2022-06-09 22:54:16,793|azureml._history.utils.context_managers|DEBUG|exiting ContentUploader, waiting for file_watcher to finish upload...\\n2022-06-09 22:54:16,793|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher called finish, setting event\\n2022-06-09 22:54:16,794|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher received exit event, getting current_stat\\n2022-06-09 22:54:16,794|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-06-09 22:54:16,795|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result|DEBUG|Using basic handler - no exception handling\\n2022-06-09 22:54:16,796|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 1_result to queue of approximate size: 1\\n2022-06-09 22:54:16,796|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher retrieved current_stat, will upload to current_stat\\n2022-06-09 22:54:16,796|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,801|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,801|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,801|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,801|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,802|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,802|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,802|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,802|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,802|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,803|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,803|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,803|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,803|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,803|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,803|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,804|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,804|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,804|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,804|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,804|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,804|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,805|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,805|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,805|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,805|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,805|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,806|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,806|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,806|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,806|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,806|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,806|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,807|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,807|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,807|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,807|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,807|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,807|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,807|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,808|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,808|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,808|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,808|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,808|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,808|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,809|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,809|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-06-09 22:54:16,810|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-06-09 22:54:16,813|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result|DEBUG|Using basic handler - no exception handling\\n2022-06-09 22:54:16,814|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 2_result to queue of approximate size: 2\\n2022-06-09 22:54:16,814|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher finished uploading to current_stat, finishing task queue\\n2022-06-09 22:54:16,814|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Stop] - waiting default timeout\\n2022-06-09 22:54:16,814|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[START]\\n2022-06-09 22:54:16,814|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Overriding default flush timeout from None to 120\\n2022-06-09 22:54:16,814|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0_result), AsyncTask(1_result), AsyncTask(2_result)].\\n2022-06-09 22:54:16,814|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[START]\\n2022-06-09 22:54:16,814|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-06-09 22:54:16,814|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[STOP]\\n2022-06-09 22:54:16,814|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[START]\\n2022-06-09 22:54:16,814|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-06-09 22:54:16,814|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[STOP]\\n2022-06-09 22:54:17,065|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[START]\\n2022-06-09 22:54:17,065|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-06-09 22:54:17,065|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[STOP]\\n2022-06-09 22:54:17,065|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Waiting on task: 2_result.\\n1 tasks left. Current duration of flush 0.00039124488830566406 seconds.\\n\\n2022-06-09 22:54:17,065|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[STOP]\\n\"},\n",
              " 'submittedBy': 'Arpan Venugopal'}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run.get_details_with_logs()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Although you can view the log details in the output above, it's usually easier to download the log files and view them in a text editor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1649363670778
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "downloaded-logs/azureml-logs/60_control_log.txt\n",
            "downloaded-logs/azureml-logs/70_driver_log.txt\n",
            "downloaded-logs/logs/azureml/8_azureml.log\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "log_folder = 'downloaded-logs'\n",
        "\n",
        "# Download all files\n",
        "run.get_all_logs(destination=log_folder)\n",
        "\n",
        "# Verify the files have been downloaded\n",
        "for root, directories, filenames in os.walk(log_folder): \n",
        "    for filename in filenames:  \n",
        "        print (os.path.join(root,filename))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View experiment run history\n",
        "\n",
        "Now that you've run the same experiment multiple times, you can view the history in [Azure Machine Learning studio](https://ml.azure.com) and explore each logged run. Or you can retrieve an experiment by name from the workspace and iterate through its runs using the SDK:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1649363706798
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run ID: mslearn-diabetes_1654815067_d3e584ca\n",
            "- observations 10000\n",
            "- Label:0 6656\n",
            "- Label:1 3344\n",
            "Run ID: e9a211fe-2cf5-43b0-beb8-b1cc4688cdf9\n",
            "- observations 10000\n",
            "- label distribution aml://artifactId/ExperimentRun/dcid.e9a211fe-2cf5-43b0-beb8-b1cc4688cdf9/label distribution_1654812925.png\n",
            "- pregnancy categories [0, 8, 7, 9, 1, 3, 5, 2, 6, 11, 4, 13, 10, 12, 14]\n",
            "- PlasmaGlucose {'stat': ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], 'value': [10000.0, 107.8502, 31.920909360565563, 44.0, 84.0, 105.0, 129.0, 192.0]}\n",
            "- DiastolicBloodPressure {'stat': ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], 'value': [10000.0, 71.2075, 16.801478289640706, 24.0, 58.0, 72.0, 85.0, 117.0]}\n",
            "- TricepsThickness {'stat': ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], 'value': [10000.0, 28.8176, 14.506480415228332, 7.0, 15.0, 31.0, 41.0, 92.0]}\n",
            "- SerumInsulin {'stat': ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], 'value': [10000.0, 139.2436, 133.77791937465278, 14.0, 39.0, 85.0, 197.0, 796.0]}\n",
            "- BMI {'stat': ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], 'value': [10000.0, 31.56702174359113, 9.804365693559113, 18.20080735, 21.247426835, 31.922420785, 39.3289214475, 56.03462763]}\n"
          ]
        }
      ],
      "source": [
        "from azureml.core import Experiment, Run\n",
        "\n",
        "diabetes_experiment = ws.experiments['mslearn-diabetes']\n",
        "for logged_run in diabetes_experiment.get_runs():\n",
        "    print('Run ID:', logged_run.id)\n",
        "    metrics = logged_run.get_metrics()\n",
        "    for key in metrics.keys():\n",
        "        print('-', key, metrics.get(key))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use MLflow\n",
        "\n",
        "MLflow is an open source platform for managing machine learning processes. It's commonly (but not exclusively) used in Databricks environments to coordinate experiments and track metrics. In Azure Machine Learning experiments, you can use MLflow to track metrics as an alternative to the native log functionality.\n",
        "\n",
        "To take advantage of this capability, you'll need the **azureml-mlflow** package, so let's ensure it's installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1649363713535
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: azureml-mlflow\n",
            "Version: 1.41.0\n",
            "Summary: Contains the integration code of AzureML with Mlflow.\n",
            "Home-page: https://docs.microsoft.com/python/api/overview/azure/ml/?view=azure-ml-py\n",
            "Author: Microsoft Corp\n",
            "Author-email: None\n",
            "License: Proprietary https://aka.ms/azureml-preview-sdk-license \n",
            "Location: /anaconda/envs/azureml_py38/lib/python3.8/site-packages\n",
            "Requires: jsonpickle, mlflow-skinny, azureml-core\n",
            "Required-by: azureml-train-automl-runtime\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip show azureml-mlflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Use MLflow with an inline experiment\n",
        "\n",
        "To use MLflow to track metrics for an inline experiment, you must set the MLflow *tracking URI* to the workspace where the experiment is being run. This enables you to use **mlflow** tracking methods to log data to the experiment run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1649363717485
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting experiment: mslearn-diabetes-mlflow\n",
            "Run complete\n"
          ]
        }
      ],
      "source": [
        "from azureml.core import Experiment\n",
        "import pandas as pd\n",
        "import mlflow\n",
        "\n",
        "# Set the MLflow tracking URI to the workspace\n",
        "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
        "\n",
        "# Create an Azure ML experiment in your workspace\n",
        "experiment = Experiment(workspace=ws, name='mslearn-diabetes-mlflow')\n",
        "mlflow.set_experiment(experiment.name)\n",
        "\n",
        "# start the MLflow experiment\n",
        "with mlflow.start_run():\n",
        "    \n",
        "    print(\"Starting experiment:\", experiment.name)\n",
        "    \n",
        "    # Load data\n",
        "    data = pd.read_csv('data/diabetes.csv')\n",
        "\n",
        "    # Count the rows and log the result\n",
        "    row_count = (len(data))\n",
        "    mlflow.log_metric('observations', row_count)\n",
        "    print(\"Run complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's look at the metrics logged during the run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1649363720202
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Metrics:\n",
            "observations 10000.0\n",
            "See details at https://ml.azure.com/experiments/id/f8274091-c7c3-466e-b866-117c928c9143?wsid=/subscriptions/73711bf5-4cda-4aca-893d-7e16cea46e36/resourcegroups/dp100/workspaces/dp100_mlws&tid=e714ef31-faab-41d2-9f1e-e6df4af16ab8\n"
          ]
        }
      ],
      "source": [
        "# Get the latest run of the experiment\n",
        "run = list(experiment.get_runs())[0]\n",
        "\n",
        "# Get logged metrics\n",
        "print(\"\\nMetrics:\")\n",
        "metrics = run.get_metrics()\n",
        "for key in metrics.keys():\n",
        "        print(key, metrics.get(key))\n",
        "    \n",
        "# Get a link to the experiment in Azure ML studio   \n",
        "experiment_url = experiment.get_portal_url()\n",
        "print('See details at', experiment_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After running the code above, you can use the link that is displayed to view the experiment in Azure Machine Learning studio. Then select the latest run of the experiment and view its **Metrics** tab to see the logged metric.\n",
        "\n",
        "### Use MLflow in an experiment script\n",
        "\n",
        "You can also use MLflow to track metrics in an experiment script.\n",
        "\n",
        "Run the following two cells to create a folder and a script for an experiment that uses MLflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1649363722917
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'mlflow-experiment-files/diabetes.csv'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os, shutil\n",
        "\n",
        "# Create a folder for the experiment files\n",
        "folder_name = 'mlflow-experiment-files'\n",
        "experiment_folder = './' + folder_name\n",
        "os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "# Copy the data file into the experiment folder\n",
        "shutil.copy('data/diabetes.csv', os.path.join(folder_name, \"diabetes.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing mlflow-experiment-files/mlflow_diabetes.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile $folder_name/mlflow_diabetes.py\n",
        "from azureml.core import Run\n",
        "import pandas as pd\n",
        "import mlflow\n",
        "\n",
        "\n",
        "# start the MLflow experiment\n",
        "with mlflow.start_run():\n",
        "       \n",
        "    # Load data\n",
        "    data = pd.read_csv('diabetes.csv')\n",
        "\n",
        "    # Count the rows and log the result\n",
        "    row_count = (len(data))\n",
        "    print('observations:', row_count)\n",
        "    mlflow.log_metric('observations', row_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When you use MLflow tracking in an Azure ML experiment script, the MLflow tracking URI is set automatically when you start the experiment run. However, the environment in which the script is to be run must include the required **mlflow** packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1649363740151
        },
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03c3cc106ca54573baee1d986859e244",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/mslearn-diabetes-mlflow_1654815974_0a392305?wsid=/subscriptions/73711bf5-4cda-4aca-893d-7e16cea46e36/resourcegroups/dp100/workspaces/dp100_mlws&tid=e714ef31-faab-41d2-9f1e-e6df4af16ab8\", \"run_id\": \"mslearn-diabetes-mlflow_1654815974_0a392305\", \"run_properties\": {\"run_id\": \"mslearn-diabetes-mlflow_1654815974_0a392305\", \"created_utc\": \"2022-06-09T23:06:14.918251Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"0da95523-76c3-48e2-9596-096252f94d58\", \"azureml.git.repository_uri\": \"https://github.com/arpan-ta/mslearn-dp100.git\", \"mlflow.source.git.repoURL\": \"https://github.com/arpan-ta/mslearn-dp100.git\", \"azureml.git.branch\": \"main\", \"mlflow.source.git.branch\": \"main\", \"azureml.git.commit\": \"d2354e40eec31c22eb09381c6a890311cccc30c9\", \"mlflow.source.git.commit\": \"d2354e40eec31c22eb09381c6a890311cccc30c9\", \"azureml.git.dirty\": \"True\"}, \"tags\": {\"mlflow.source.type\": \"JOB\", \"mlflow.source.name\": \"mlflow_diabetes.py\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2022-06-09T23:06:27.215549Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://dp100mlws7512094280.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes-mlflow_1654815974_0a392305/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=RJ9FNNJHsIHtUzL3tk4cxIONkDZekpcsCw2n%2BzWeqVA%3D&skoid=aa567b24-7487-4111-90c5-f77419aa7dff&sktid=e714ef31-faab-41d2-9f1e-e6df4af16ab8&skt=2022-06-09T22%3A05%3A26Z&ske=2022-06-11T06%3A15%3A26Z&sks=b&skv=2019-07-07&st=2022-06-09T23%3A01%3A38Z&se=2022-06-10T07%3A11%3A38Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://dp100mlws7512094280.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes-mlflow_1654815974_0a392305/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=083x5S3cJLxe3xPyx6w7qNNZtSTeziuEUA1iCX5YXMU%3D&skoid=aa567b24-7487-4111-90c5-f77419aa7dff&sktid=e714ef31-faab-41d2-9f1e-e6df4af16ab8&skt=2022-06-09T22%3A05%3A26Z&ske=2022-06-11T06%3A15%3A26Z&sks=b&skv=2019-07-07&st=2022-06-09T23%3A01%3A38Z&se=2022-06-10T07%3A11%3A38Z&sp=r\", \"logs/azureml/8_azureml.log\": \"https://dp100mlws7512094280.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes-mlflow_1654815974_0a392305/logs/azureml/8_azureml.log?sv=2019-07-07&sr=b&sig=LKgDsJRooi4l%2BGX4s2f0LVdFm4aqgCo7j9Z8NgbtL64%3D&skoid=aa567b24-7487-4111-90c5-f77419aa7dff&sktid=e714ef31-faab-41d2-9f1e-e6df4af16ab8&skt=2022-06-09T22%3A05%3A26Z&ske=2022-06-11T06%3A15%3A26Z&sks=b&skv=2019-07-07&st=2022-06-09T23%3A01%3A38Z&se=2022-06-10T07%3A11%3A38Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/8_azureml.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"]], \"run_duration\": \"0:00:12\", \"run_number\": \"1654815974\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"observations\", \"run_id\": \"mslearn-diabetes-mlflow_1654815974_0a392305\", \"categories\": [0], \"series\": [{\"data\": [10000.0]}]}], \"run_logs\": \"[2022-06-09T23:06:17.606575] Entering context manager injector.\\nCannot provide tracer without any exporter configured.\\n[2022-06-09T23:06:18.230616] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['mlflow_diabetes.py'])\\nScript type = None\\n[2022-06-09T23:06:18.233179] Entering Run History Context Manager.\\n/azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib/python3.6/site-packages/azureml/history/_tracking.py:186: FutureWarning: MLflow support for Python 3.6 is deprecated and will be dropped in an upcoming release. At that point, existing Python 3.6 workflows that use MLflow will continue to work without modification, but Python 3.6 users will no longer get access to the latest MLflow features and bugfixes. We recommend that you upgrade to Python 3.7 or newer.\\n  import mlflow\\n[2022-06-09T23:06:20.195254] Current directory: /azureml-run\\n[2022-06-09T23:06:20.195284] Preparing to call script [mlflow_diabetes.py] with arguments:[]\\n[2022-06-09T23:06:20.195302] After variable expansion, calling script [mlflow_diabetes.py] with arguments:[]\\n\\nobservations: 10000\\n\\n\\n[2022-06-09T23:06:21.029905] The experiment completed successfully. Finalizing run...\\n[2022-06-09T23:06:21.029926] Start FinalizingInRunHistory\\n[2022-06-09T23:06:21.031365] Logging experiment finalizing status in history service.\\nStarting the daemon thread to refresh tokens in background for process with pid = 8\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\n1 items cleaning up...\\nCleanup took 0.04807567596435547 seconds\\n[2022-06-09T23:06:25.903915] Finished context manager injector.\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.41.0\"}, \"loading\": false}"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'runId': 'mslearn-diabetes-mlflow_1654815974_0a392305',\n",
              " 'target': 'local',\n",
              " 'status': 'Finalizing',\n",
              " 'startTimeUtc': '2022-06-09T23:06:16.548358Z',\n",
              " 'services': {},\n",
              " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
              "  'ContentSnapshotId': '0da95523-76c3-48e2-9596-096252f94d58',\n",
              "  'azureml.git.repository_uri': 'https://github.com/arpan-ta/mslearn-dp100.git',\n",
              "  'mlflow.source.git.repoURL': 'https://github.com/arpan-ta/mslearn-dp100.git',\n",
              "  'azureml.git.branch': 'main',\n",
              "  'mlflow.source.git.branch': 'main',\n",
              "  'azureml.git.commit': 'd2354e40eec31c22eb09381c6a890311cccc30c9',\n",
              "  'mlflow.source.git.commit': 'd2354e40eec31c22eb09381c6a890311cccc30c9',\n",
              "  'azureml.git.dirty': 'True'},\n",
              " 'inputDatasets': [],\n",
              " 'outputDatasets': [],\n",
              " 'runDefinition': {'script': 'mlflow_diabetes.py',\n",
              "  'command': '',\n",
              "  'useAbsolutePath': False,\n",
              "  'arguments': [],\n",
              "  'sourceDirectoryDataStore': None,\n",
              "  'framework': 'Python',\n",
              "  'communicator': 'None',\n",
              "  'target': 'local',\n",
              "  'dataReferences': {},\n",
              "  'data': {},\n",
              "  'outputData': {},\n",
              "  'datacaches': [],\n",
              "  'jobName': None,\n",
              "  'maxRunDurationSeconds': 2592000,\n",
              "  'nodeCount': 1,\n",
              "  'instanceTypes': [],\n",
              "  'priority': None,\n",
              "  'credentialPassthrough': False,\n",
              "  'identity': None,\n",
              "  'environment': {'name': 'experiment_env',\n",
              "   'version': 'Autosave_2022-06-09T22:51:08Z_fa73d59d',\n",
              "   'python': {'interpreterPath': 'python',\n",
              "    'userManagedDependencies': False,\n",
              "    'condaDependencies': {'dependencies': ['python=3.6.2',\n",
              "      'scikit-learn',\n",
              "      'pandas',\n",
              "      'pip',\n",
              "      {'pip': ['azureml-defaults', 'azureml-mlflow']}],\n",
              "     'name': 'simple_environment'},\n",
              "    'baseCondaEnvironment': None},\n",
              "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
              "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220412.v1',\n",
              "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
              "    'baseDockerfile': None,\n",
              "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
              "    'enabled': False,\n",
              "    'arguments': []},\n",
              "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
              "   'inferencingStackVersion': None},\n",
              "  'history': {'outputCollection': True,\n",
              "   'directoriesToWatch': ['logs'],\n",
              "   'enableMLflowTracking': True,\n",
              "   'snapshotProject': True},\n",
              "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
              "    'spark.yarn.maxAppAttempts': '1'}},\n",
              "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
              "   'workerCountPerNode': 1,\n",
              "   'terminalExitCodes': None,\n",
              "   'configuration': {}},\n",
              "  'amlCompute': {'name': None,\n",
              "   'vmSize': None,\n",
              "   'retainCluster': False,\n",
              "   'clusterMaxNodeCount': None},\n",
              "  'aiSuperComputer': {'instanceType': 'D2',\n",
              "   'imageVersion': 'pytorch-1.7.0',\n",
              "   'location': None,\n",
              "   'aiSuperComputerStorageData': None,\n",
              "   'interactive': False,\n",
              "   'scalePolicy': None,\n",
              "   'virtualClusterArmId': None,\n",
              "   'tensorboardLogDirectory': None,\n",
              "   'sshPublicKey': None,\n",
              "   'sshPublicKeys': None,\n",
              "   'enableAzmlInt': True,\n",
              "   'priority': 'Medium',\n",
              "   'slaTier': 'Standard',\n",
              "   'userAlias': None},\n",
              "  'kubernetesCompute': {'instanceType': None},\n",
              "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
              "  'mpi': {'processCountPerNode': 1},\n",
              "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
              "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
              "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
              "  'exposedPorts': None,\n",
              "  'docker': {'useDocker': True,\n",
              "   'sharedVolumes': True,\n",
              "   'shmSize': '2g',\n",
              "   'arguments': []},\n",
              "  'cmk8sCompute': {'configuration': {}},\n",
              "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
              "   'successfulReturnCodes': []},\n",
              "  'environmentVariables': {},\n",
              "  'applicationEndpoints': {},\n",
              "  'parameters': []},\n",
              " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://dp100mlws7512094280.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes-mlflow_1654815974_0a392305/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=IKw9iGSJ%2Fml6qfp7r6S86wfpfKpUt%2BtKfq9rBdZxOqI%3D&skoid=aa567b24-7487-4111-90c5-f77419aa7dff&sktid=e714ef31-faab-41d2-9f1e-e6df4af16ab8&skt=2022-06-09T22%3A05%3A26Z&ske=2022-06-11T06%3A15%3A26Z&sks=b&skv=2019-07-07&st=2022-06-09T22%3A56%3A22Z&se=2022-06-10T07%3A06%3A22Z&sp=r',\n",
              "  'azureml-logs/70_driver_log.txt': 'https://dp100mlws7512094280.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes-mlflow_1654815974_0a392305/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=rRYhqjKAU1JOGJ48ibmpVmx1T9UBzqgP3Ah4%2BwjjpzQ%3D&skoid=aa567b24-7487-4111-90c5-f77419aa7dff&sktid=e714ef31-faab-41d2-9f1e-e6df4af16ab8&skt=2022-06-09T22%3A05%3A26Z&ske=2022-06-11T06%3A15%3A26Z&sks=b&skv=2019-07-07&st=2022-06-09T22%3A56%3A22Z&se=2022-06-10T07%3A06%3A22Z&sp=r'},\n",
              " 'submittedBy': 'Arpan Venugopal'}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
        "from azureml.core.runconfig import DockerConfiguration\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "\n",
        "# Create a Python environment for the experiment (from a .yml file)\n",
        "env = Environment.from_conda_specification(\"experiment_env\", \"environment.yml\")\n",
        "\n",
        "# Create a script config\n",
        "script_mlflow = ScriptRunConfig(source_directory=experiment_folder,\n",
        "                                script='mlflow_diabetes.py',\n",
        "                                environment=env,\n",
        "                                docker_runtime_config=DockerConfiguration(use_docker=True)) \n",
        "\n",
        "# submit the experiment\n",
        "experiment = Experiment(workspace=ws, name='mslearn-diabetes-mlflow')\n",
        "run = experiment.submit(config=script_mlflow)\n",
        "RunDetails(run).show()\n",
        "run.wait_for_completion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As usual, you can get the logged metrics from the experiment run when it's finished."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1649363744091
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "observations 10000.0\n"
          ]
        }
      ],
      "source": [
        "# Get logged metrics\n",
        "metrics = run.get_metrics()\n",
        "for key in metrics.keys():\n",
        "        print(key, metrics.get(key))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **More Information**: To find out more about running experiments, see [this topic](https://docs.microsoft.com/azure/machine-learning/how-to-manage-runs) in the Azure ML documentation. For details of how to log metrics in a run, see [this topic](https://docs.microsoft.com/azure/machine-learning/how-to-track-experiments). For more information about integrating Azure ML experiments with MLflow, see [this topic](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-mlflow)."
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
